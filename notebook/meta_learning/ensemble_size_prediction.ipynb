{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import itertools\n",
    "import random\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>hurst</th>\n",
       "      <th>series_length</th>\n",
       "      <th>unitroot_pp</th>\n",
       "      <th>unitroot_kpss</th>\n",
       "      <th>hw_alpha</th>\n",
       "      <th>hw_beta</th>\n",
       "      <th>hw_gamma</th>\n",
       "      <th>stability</th>\n",
       "      <th>nperiods</th>\n",
       "      <th>...</th>\n",
       "      <th>diff1_acf10</th>\n",
       "      <th>diff2_acf1</th>\n",
       "      <th>diff2_acf10</th>\n",
       "      <th>seas_acf1</th>\n",
       "      <th>exponential_smoothing</th>\n",
       "      <th>arima</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>model_rank</th>\n",
       "      <th>ensemble_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artificialNoAnomaly/art_daily_no_noise.csv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4032</td>\n",
       "      <td>-45.198782</td>\n",
       "      <td>0.046765</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.000000e-04</td>\n",
       "      <td>2.500000e-01</td>\n",
       "      <td>1.050000e-62</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.970000e-26</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>22.402977</td>\n",
       "      <td>25.282784</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>0.003701</td>\n",
       "      <td>['random_forest', 'xgboost', 'exponential_smoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>artificialNoAnomaly/art_daily_perfect_square_w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4032</td>\n",
       "      <td>-63.887428</td>\n",
       "      <td>0.043267</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>1.750000e-01</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>22.385788</td>\n",
       "      <td>26.668146</td>\n",
       "      <td>0.009475</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>['random_forest', 'xgboost', 'exponential_smoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>artificialNoAnomaly/art_daily_small_noise.csv</td>\n",
       "      <td>0.412716</td>\n",
       "      <td>4032</td>\n",
       "      <td>-57.839587</td>\n",
       "      <td>0.046790</td>\n",
       "      <td>1.490000e-08</td>\n",
       "      <td>1.010000e-08</td>\n",
       "      <td>3.110000e-21</td>\n",
       "      <td>1.280000e-05</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.206679e-02</td>\n",
       "      <td>-0.620340</td>\n",
       "      <td>0.418001</td>\n",
       "      <td>0.918527</td>\n",
       "      <td>22.720717</td>\n",
       "      <td>25.473923</td>\n",
       "      <td>2.009846</td>\n",
       "      <td>2.076357</td>\n",
       "      <td>['xgboost', 'random_forest', 'exponential_smoo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>artificialNoAnomaly/art_noisy.csv</td>\n",
       "      <td>0.507001</td>\n",
       "      <td>4032</td>\n",
       "      <td>-4126.670693</td>\n",
       "      <td>0.299753</td>\n",
       "      <td>1.580000e-08</td>\n",
       "      <td>7.610000e-09</td>\n",
       "      <td>2.480000e-06</td>\n",
       "      <td>5.353556e-03</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.664287e-01</td>\n",
       "      <td>-0.676908</td>\n",
       "      <td>0.497557</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>2.872416</td>\n",
       "      <td>2.820160</td>\n",
       "      <td>2.820342</td>\n",
       "      <td>2.883200</td>\n",
       "      <td>['xgboost', 'exponential_smoothing', 'random_f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificialWithAnomaly/art_daily_flatmiddle.csv</td>\n",
       "      <td>0.501646</td>\n",
       "      <td>4032</td>\n",
       "      <td>-49.327420</td>\n",
       "      <td>0.121571</td>\n",
       "      <td>5.372404e-01</td>\n",
       "      <td>1.590000e-07</td>\n",
       "      <td>2.630000e-07</td>\n",
       "      <td>1.456821e-02</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.705510e-02</td>\n",
       "      <td>-0.553618</td>\n",
       "      <td>0.314774</td>\n",
       "      <td>0.833093</td>\n",
       "      <td>33.442868</td>\n",
       "      <td>39.067347</td>\n",
       "      <td>13.022835</td>\n",
       "      <td>13.046776</td>\n",
       "      <td>['xgboost', 'random_forest', 'exponential_smoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           unique_id     hurst  series_length  \\\n",
       "0         artificialNoAnomaly/art_daily_no_noise.csv       NaN           4032   \n",
       "1  artificialNoAnomaly/art_daily_perfect_square_w...       NaN           4032   \n",
       "2      artificialNoAnomaly/art_daily_small_noise.csv  0.412716           4032   \n",
       "3                  artificialNoAnomaly/art_noisy.csv  0.507001           4032   \n",
       "4     artificialWithAnomaly/art_daily_flatmiddle.csv  0.501646           4032   \n",
       "\n",
       "   unitroot_pp  unitroot_kpss      hw_alpha       hw_beta      hw_gamma  \\\n",
       "0   -45.198782       0.046765  5.000000e-01  1.000000e-04  2.500000e-01   \n",
       "1   -63.887428       0.043267  5.000000e-01  1.750000e-01  2.000000e-01   \n",
       "2   -57.839587       0.046790  1.490000e-08  1.010000e-08  3.110000e-21   \n",
       "3 -4126.670693       0.299753  1.580000e-08  7.610000e-09  2.480000e-06   \n",
       "4   -49.327420       0.121571  5.372404e-01  1.590000e-07  2.630000e-07   \n",
       "\n",
       "      stability  nperiods  ...   diff1_acf10  diff2_acf1  diff2_acf10  \\\n",
       "0  1.050000e-62         1  ...  2.970000e-26   -0.500000     0.250000   \n",
       "1  0.000000e+00         1  ...  0.000000e+00   -0.500000     0.250000   \n",
       "2  1.280000e-05         1  ...  8.206679e-02   -0.620340     0.418001   \n",
       "3  5.353556e-03         1  ...  2.664287e-01   -0.676908     0.497557   \n",
       "4  1.456821e-02         1  ...  1.705510e-02   -0.553618     0.314774   \n",
       "\n",
       "   seas_acf1  exponential_smoothing      arima    xgboost  random_forest  \\\n",
       "0   0.928571              22.402977  25.282784   0.011355       0.003701   \n",
       "1   0.928571              22.385788  26.668146   0.009475       0.000024   \n",
       "2   0.918527              22.720717  25.473923   2.009846       2.076357   \n",
       "3   0.005106               2.872416   2.820160   2.820342       2.883200   \n",
       "4   0.833093              33.442868  39.067347  13.022835      13.046776   \n",
       "\n",
       "                                          model_rank  ensemble_size  \n",
       "0  ['random_forest', 'xgboost', 'exponential_smoo...              1  \n",
       "1  ['random_forest', 'xgboost', 'exponential_smoo...              1  \n",
       "2  ['xgboost', 'random_forest', 'exponential_smoo...              2  \n",
       "3  ['xgboost', 'exponential_smoothing', 'random_f...              1  \n",
       "4  ['xgboost', 'random_forest', 'exponential_smoo...              1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_size_df = pd.read_csv('../dataset_preparation/df_features_with_ensemble_size_2.csv')\n",
    "ensemble_size_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unique_id', 'hurst', 'series_length', 'unitroot_pp', 'unitroot_kpss',\n",
       "       'hw_alpha', 'hw_beta', 'hw_gamma', 'stability', 'nperiods',\n",
       "       'seasonal_period', 'trend', 'spike', 'linearity', 'curvature', 'e_acf1',\n",
       "       'e_acf10', 'seasonal_strength', 'peak', 'trough', 'x_pacf5',\n",
       "       'diff1x_pacf5', 'diff2x_pacf5', 'seas_pacf', 'nonlinearity',\n",
       "       'lumpiness', 'alpha', 'beta', 'arch_acf', 'garch_acf', 'arch_r2',\n",
       "       'garch_r2', 'flat_spots', 'entropy', 'crossing_points', 'arch_lm',\n",
       "       'x_acf1', 'x_acf10', 'diff1_acf1', 'diff1_acf10', 'diff2_acf1',\n",
       "       'diff2_acf10', 'seas_acf1', 'exponential_smoothing', 'arima', 'xgboost',\n",
       "       'random_forest', 'model_rank', 'ensemble_size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_size_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_mapping = {\n",
    "    'series_length':'series_length',\n",
    "    'stability': 'stability',\n",
    "    'lumpiness': 'lumpiness',\n",
    "    'crossing.points.fraction': 'crossing_points',  \n",
    "    'flat.spots.fraction': 'flat_spots',  \n",
    "    'nonlinearity': 'nonlinearity',\n",
    "    'ur.kpss': 'unitroot_kpss',\n",
    "    'ur.pp': 'unitroot_pp',\n",
    "    'arch.lm': 'arch_lm',\n",
    "    'ACF1': 'x_acf1',\n",
    "    'ACF10.SS': 'x_acf10',\n",
    "    'ACF.seas': 'seas_acf1',\n",
    "    'PACF10.SS': 'x_pacf5',\n",
    "    'PACF.seas': 'seas_pacf',\n",
    "    'hurst': 'hurst',\n",
    "    'ensemble_size':'ensemble_size'\n",
    "}\n",
    "\n",
    "# Check for columns that are not present in the original DataFrame\n",
    "missing_columns = [col for col in column_mapping.values() if col not in ensemble_size_df.columns]\n",
    "\n",
    "missing_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_length</th>\n",
       "      <th>stability</th>\n",
       "      <th>lumpiness</th>\n",
       "      <th>crossing_points</th>\n",
       "      <th>flat_spots</th>\n",
       "      <th>nonlinearity</th>\n",
       "      <th>unitroot_kpss</th>\n",
       "      <th>unitroot_pp</th>\n",
       "      <th>arch_lm</th>\n",
       "      <th>x_acf1</th>\n",
       "      <th>x_acf10</th>\n",
       "      <th>seas_acf1</th>\n",
       "      <th>x_pacf5</th>\n",
       "      <th>seas_pacf</th>\n",
       "      <th>hurst</th>\n",
       "      <th>ensemble_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4032</td>\n",
       "      <td>1.050000e-62</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.046765</td>\n",
       "      <td>-45.198782</td>\n",
       "      <td>0.960470</td>\n",
       "      <td>0.989173</td>\n",
       "      <td>8.854128</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.978583</td>\n",
       "      <td>-0.007057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4032</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.043267</td>\n",
       "      <td>-63.887428</td>\n",
       "      <td>0.970557</td>\n",
       "      <td>0.985036</td>\n",
       "      <td>8.440207</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.970529</td>\n",
       "      <td>-0.006061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4032</td>\n",
       "      <td>1.280000e-05</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>490</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2.349718</td>\n",
       "      <td>0.046790</td>\n",
       "      <td>-57.839587</td>\n",
       "      <td>0.726378</td>\n",
       "      <td>0.977531</td>\n",
       "      <td>8.643415</td>\n",
       "      <td>0.918527</td>\n",
       "      <td>1.027842</td>\n",
       "      <td>0.205044</td>\n",
       "      <td>0.412716</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4032</td>\n",
       "      <td>5.353556e-03</td>\n",
       "      <td>0.003807</td>\n",
       "      <td>2049</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.007447</td>\n",
       "      <td>0.299753</td>\n",
       "      <td>-4126.670693</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>-0.009305</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.007050</td>\n",
       "      <td>0.507001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4032</td>\n",
       "      <td>1.456821e-02</td>\n",
       "      <td>0.074039</td>\n",
       "      <td>50</td>\n",
       "      <td>276.0</td>\n",
       "      <td>0.741962</td>\n",
       "      <td>0.121571</td>\n",
       "      <td>-49.327420</td>\n",
       "      <td>0.859136</td>\n",
       "      <td>0.985528</td>\n",
       "      <td>8.769812</td>\n",
       "      <td>0.833093</td>\n",
       "      <td>0.984697</td>\n",
       "      <td>0.138940</td>\n",
       "      <td>0.501646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4032</td>\n",
       "      <td>2.104731e-02</td>\n",
       "      <td>0.061766</td>\n",
       "      <td>494</td>\n",
       "      <td>168.0</td>\n",
       "      <td>2.052138</td>\n",
       "      <td>0.098380</td>\n",
       "      <td>-55.541723</td>\n",
       "      <td>0.781880</td>\n",
       "      <td>0.978055</td>\n",
       "      <td>8.682667</td>\n",
       "      <td>0.861524</td>\n",
       "      <td>1.028455</td>\n",
       "      <td>0.172089</td>\n",
       "      <td>0.523080</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4032</td>\n",
       "      <td>4.711886e-02</td>\n",
       "      <td>0.564556</td>\n",
       "      <td>481</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.260825</td>\n",
       "      <td>-53.046075</td>\n",
       "      <td>0.922626</td>\n",
       "      <td>0.980089</td>\n",
       "      <td>8.726534</td>\n",
       "      <td>0.817634</td>\n",
       "      <td>1.027627</td>\n",
       "      <td>0.142922</td>\n",
       "      <td>0.565294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4032</td>\n",
       "      <td>4.757963e-02</td>\n",
       "      <td>0.076025</td>\n",
       "      <td>655</td>\n",
       "      <td>456.0</td>\n",
       "      <td>2.275400</td>\n",
       "      <td>0.185286</td>\n",
       "      <td>-52.591420</td>\n",
       "      <td>0.783589</td>\n",
       "      <td>0.979942</td>\n",
       "      <td>8.714155</td>\n",
       "      <td>0.796279</td>\n",
       "      <td>1.015332</td>\n",
       "      <td>0.142267</td>\n",
       "      <td>0.553390</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4032</td>\n",
       "      <td>4.910010e-04</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>167</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-0.005879</td>\n",
       "      <td>0.008390</td>\n",
       "      <td>-4751.528222</td>\n",
       "      <td>0.298665</td>\n",
       "      <td>-0.009269</td>\n",
       "      <td>0.224518</td>\n",
       "      <td>-0.020033</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>-0.011985</td>\n",
       "      <td>0.324410</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4032</td>\n",
       "      <td>1.664999e-01</td>\n",
       "      <td>1.929794</td>\n",
       "      <td>374</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.164389</td>\n",
       "      <td>1.734170</td>\n",
       "      <td>-1639.435252</td>\n",
       "      <td>0.270885</td>\n",
       "      <td>0.605997</td>\n",
       "      <td>0.637076</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.393273</td>\n",
       "      <td>0.017855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4032</td>\n",
       "      <td>2.084299e-03</td>\n",
       "      <td>0.282101</td>\n",
       "      <td>572</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.066191</td>\n",
       "      <td>0.209819</td>\n",
       "      <td>-4111.795313</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>-0.040142</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.109389</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.126549</td>\n",
       "      <td>0.542713</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4032</td>\n",
       "      <td>1.468810e-02</td>\n",
       "      <td>0.017492</td>\n",
       "      <td>2248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.029477</td>\n",
       "      <td>2.076331</td>\n",
       "      <td>-5479.608260</td>\n",
       "      <td>0.039873</td>\n",
       "      <td>-0.117574</td>\n",
       "      <td>0.446556</td>\n",
       "      <td>0.571083</td>\n",
       "      <td>0.027830</td>\n",
       "      <td>0.070232</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4032</td>\n",
       "      <td>5.619322e-01</td>\n",
       "      <td>0.072827</td>\n",
       "      <td>1533</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.944388</td>\n",
       "      <td>31.742803</td>\n",
       "      <td>-6910.253390</td>\n",
       "      <td>0.301557</td>\n",
       "      <td>0.303370</td>\n",
       "      <td>2.948069</td>\n",
       "      <td>0.413182</td>\n",
       "      <td>0.971923</td>\n",
       "      <td>-0.016033</td>\n",
       "      <td>1.592583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4032</td>\n",
       "      <td>7.676587e-02</td>\n",
       "      <td>0.355272</td>\n",
       "      <td>1691</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.067505</td>\n",
       "      <td>0.489215</td>\n",
       "      <td>-654.999557</td>\n",
       "      <td>0.587577</td>\n",
       "      <td>0.818554</td>\n",
       "      <td>1.326405</td>\n",
       "      <td>0.116130</td>\n",
       "      <td>0.733038</td>\n",
       "      <td>0.028988</td>\n",
       "      <td>0.950880</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4034</td>\n",
       "      <td>4.826812e-01</td>\n",
       "      <td>3.619413</td>\n",
       "      <td>851</td>\n",
       "      <td>320.0</td>\n",
       "      <td>1.248847</td>\n",
       "      <td>1.451362</td>\n",
       "      <td>-62.565968</td>\n",
       "      <td>0.970268</td>\n",
       "      <td>0.969111</td>\n",
       "      <td>8.553823</td>\n",
       "      <td>0.012096</td>\n",
       "      <td>1.036640</td>\n",
       "      <td>0.008338</td>\n",
       "      <td>1.023656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4037</td>\n",
       "      <td>8.348266e-01</td>\n",
       "      <td>0.345937</td>\n",
       "      <td>1638</td>\n",
       "      <td>456.0</td>\n",
       "      <td>1.939950</td>\n",
       "      <td>12.161875</td>\n",
       "      <td>-8.202838</td>\n",
       "      <td>0.996375</td>\n",
       "      <td>0.988133</td>\n",
       "      <td>9.567909</td>\n",
       "      <td>0.320249</td>\n",
       "      <td>1.223311</td>\n",
       "      <td>0.014974</td>\n",
       "      <td>1.089914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4032</td>\n",
       "      <td>1.471170e-04</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>2207</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.102933</td>\n",
       "      <td>0.045319</td>\n",
       "      <td>-4057.127914</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.037444</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.195534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4032</td>\n",
       "      <td>2.957167e-02</td>\n",
       "      <td>0.348292</td>\n",
       "      <td>769</td>\n",
       "      <td>777.0</td>\n",
       "      <td>0.217334</td>\n",
       "      <td>0.200876</td>\n",
       "      <td>-992.787092</td>\n",
       "      <td>0.366378</td>\n",
       "      <td>0.726203</td>\n",
       "      <td>0.896081</td>\n",
       "      <td>0.084554</td>\n",
       "      <td>0.659281</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>0.802616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4730</td>\n",
       "      <td>1.844837e-02</td>\n",
       "      <td>1.138475</td>\n",
       "      <td>228</td>\n",
       "      <td>573.0</td>\n",
       "      <td>2.697196</td>\n",
       "      <td>1.035371</td>\n",
       "      <td>-3490.599993</td>\n",
       "      <td>0.078363</td>\n",
       "      <td>0.250538</td>\n",
       "      <td>0.077008</td>\n",
       "      <td>0.018929</td>\n",
       "      <td>0.062992</td>\n",
       "      <td>0.017607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4032</td>\n",
       "      <td>2.948414e-02</td>\n",
       "      <td>0.802886</td>\n",
       "      <td>424</td>\n",
       "      <td>507.0</td>\n",
       "      <td>1.204699</td>\n",
       "      <td>0.374319</td>\n",
       "      <td>-3277.146318</td>\n",
       "      <td>0.095276</td>\n",
       "      <td>0.367030</td>\n",
       "      <td>0.315850</td>\n",
       "      <td>0.045452</td>\n",
       "      <td>0.160580</td>\n",
       "      <td>-0.003655</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4034</td>\n",
       "      <td>1.474807e-02</td>\n",
       "      <td>13.082651</td>\n",
       "      <td>972</td>\n",
       "      <td>2387.0</td>\n",
       "      <td>0.115234</td>\n",
       "      <td>0.781227</td>\n",
       "      <td>-4253.857995</td>\n",
       "      <td>0.096123</td>\n",
       "      <td>0.192525</td>\n",
       "      <td>0.209505</td>\n",
       "      <td>0.028128</td>\n",
       "      <td>0.201885</td>\n",
       "      <td>0.006898</td>\n",
       "      <td>0.997192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4730</td>\n",
       "      <td>1.436679e-02</td>\n",
       "      <td>0.615856</td>\n",
       "      <td>2575</td>\n",
       "      <td>573.0</td>\n",
       "      <td>0.030949</td>\n",
       "      <td>0.287323</td>\n",
       "      <td>-5126.039828</td>\n",
       "      <td>0.043917</td>\n",
       "      <td>0.039702</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.857048</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4040</td>\n",
       "      <td>3.687169e-02</td>\n",
       "      <td>0.068264</td>\n",
       "      <td>1730</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.624592</td>\n",
       "      <td>-4307.441063</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>0.228100</td>\n",
       "      <td>0.200517</td>\n",
       "      <td>0.085739</td>\n",
       "      <td>0.085064</td>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.838219</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4621</td>\n",
       "      <td>1.025456e+00</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>1779</td>\n",
       "      <td>252.0</td>\n",
       "      <td>2.485430</td>\n",
       "      <td>20.719757</td>\n",
       "      <td>-12.709826</td>\n",
       "      <td>0.972019</td>\n",
       "      <td>0.987206</td>\n",
       "      <td>9.552269</td>\n",
       "      <td>0.638466</td>\n",
       "      <td>1.155846</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>1.246498</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1243</td>\n",
       "      <td>1.322639e-01</td>\n",
       "      <td>3.139152</td>\n",
       "      <td>100</td>\n",
       "      <td>280.0</td>\n",
       "      <td>0.092818</td>\n",
       "      <td>0.749119</td>\n",
       "      <td>-106.161577</td>\n",
       "      <td>0.884200</td>\n",
       "      <td>0.926089</td>\n",
       "      <td>3.152482</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>1.031682</td>\n",
       "      <td>-0.014541</td>\n",
       "      <td>0.692340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4033</td>\n",
       "      <td>9.581317e-01</td>\n",
       "      <td>0.116058</td>\n",
       "      <td>1370</td>\n",
       "      <td>343.0</td>\n",
       "      <td>1.637593</td>\n",
       "      <td>21.725077</td>\n",
       "      <td>-23.910583</td>\n",
       "      <td>0.875012</td>\n",
       "      <td>0.975589</td>\n",
       "      <td>9.438414</td>\n",
       "      <td>0.659690</td>\n",
       "      <td>1.403919</td>\n",
       "      <td>0.063786</td>\n",
       "      <td>1.166369</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4032</td>\n",
       "      <td>9.279393e-01</td>\n",
       "      <td>0.093072</td>\n",
       "      <td>1089</td>\n",
       "      <td>946.0</td>\n",
       "      <td>0.863567</td>\n",
       "      <td>20.102611</td>\n",
       "      <td>-64.770967</td>\n",
       "      <td>0.398552</td>\n",
       "      <td>0.959303</td>\n",
       "      <td>8.730561</td>\n",
       "      <td>0.628451</td>\n",
       "      <td>1.093730</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>1.294494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1648</td>\n",
       "      <td>1.644120e-01</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>219</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.320453</td>\n",
       "      <td>3.322436</td>\n",
       "      <td>-291.651096</td>\n",
       "      <td>0.333751</td>\n",
       "      <td>0.844560</td>\n",
       "      <td>1.723964</td>\n",
       "      <td>0.533564</td>\n",
       "      <td>0.745947</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.906114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1648</td>\n",
       "      <td>4.131772e-02</td>\n",
       "      <td>0.054246</td>\n",
       "      <td>228</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.353326</td>\n",
       "      <td>0.688890</td>\n",
       "      <td>-352.407911</td>\n",
       "      <td>0.270601</td>\n",
       "      <td>0.823062</td>\n",
       "      <td>2.040337</td>\n",
       "      <td>0.601838</td>\n",
       "      <td>0.782421</td>\n",
       "      <td>-0.010624</td>\n",
       "      <td>0.720425</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1647</td>\n",
       "      <td>7.298716e-02</td>\n",
       "      <td>0.414012</td>\n",
       "      <td>361</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.513498</td>\n",
       "      <td>0.784406</td>\n",
       "      <td>-689.702090</td>\n",
       "      <td>0.243241</td>\n",
       "      <td>0.595922</td>\n",
       "      <td>0.603031</td>\n",
       "      <td>0.155811</td>\n",
       "      <td>0.379640</td>\n",
       "      <td>-0.054273</td>\n",
       "      <td>0.827410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1647</td>\n",
       "      <td>1.435551e-01</td>\n",
       "      <td>0.272551</td>\n",
       "      <td>257</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.757995</td>\n",
       "      <td>3.913879</td>\n",
       "      <td>-377.537596</td>\n",
       "      <td>0.098898</td>\n",
       "      <td>0.764779</td>\n",
       "      <td>1.248005</td>\n",
       "      <td>0.290427</td>\n",
       "      <td>0.591957</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.898996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1647</td>\n",
       "      <td>2.671595e-02</td>\n",
       "      <td>1.962780</td>\n",
       "      <td>287</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.344567</td>\n",
       "      <td>1.727024</td>\n",
       "      <td>-1862.138673</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.040633</td>\n",
       "      <td>0.032792</td>\n",
       "      <td>-0.000595</td>\n",
       "      <td>0.028190</td>\n",
       "      <td>-0.011528</td>\n",
       "      <td>0.520317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1647</td>\n",
       "      <td>1.118297e-02</td>\n",
       "      <td>1.921403</td>\n",
       "      <td>315</td>\n",
       "      <td>488.0</td>\n",
       "      <td>0.278744</td>\n",
       "      <td>0.181736</td>\n",
       "      <td>-1839.697103</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.030553</td>\n",
       "      <td>0.026503</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.024306</td>\n",
       "      <td>-0.020632</td>\n",
       "      <td>0.390779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7888</td>\n",
       "      <td>6.982387e-01</td>\n",
       "      <td>0.043476</td>\n",
       "      <td>501</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>15.832975</td>\n",
       "      <td>-157.619180</td>\n",
       "      <td>0.918206</td>\n",
       "      <td>0.977310</td>\n",
       "      <td>8.132260</td>\n",
       "      <td>0.523375</td>\n",
       "      <td>1.052754</td>\n",
       "      <td>-0.014149</td>\n",
       "      <td>1.085836</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>18050</td>\n",
       "      <td>7.755582e-02</td>\n",
       "      <td>0.233056</td>\n",
       "      <td>5441</td>\n",
       "      <td>167.0</td>\n",
       "      <td>1.885470</td>\n",
       "      <td>8.482093</td>\n",
       "      <td>-10076.273860</td>\n",
       "      <td>0.656113</td>\n",
       "      <td>0.434372</td>\n",
       "      <td>0.202673</td>\n",
       "      <td>0.755177</td>\n",
       "      <td>0.216052</td>\n",
       "      <td>-0.021728</td>\n",
       "      <td>0.645124</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4033</td>\n",
       "      <td>5.518243e-02</td>\n",
       "      <td>0.510129</td>\n",
       "      <td>2275</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.244981</td>\n",
       "      <td>1.397734</td>\n",
       "      <td>-7018.692276</td>\n",
       "      <td>0.045816</td>\n",
       "      <td>-0.141438</td>\n",
       "      <td>0.176783</td>\n",
       "      <td>0.093253</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.027901</td>\n",
       "      <td>0.994541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>22683</td>\n",
       "      <td>7.228339e-01</td>\n",
       "      <td>0.357257</td>\n",
       "      <td>975</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.025294</td>\n",
       "      <td>2.419612</td>\n",
       "      <td>-85.740275</td>\n",
       "      <td>0.993368</td>\n",
       "      <td>0.996905</td>\n",
       "      <td>9.686593</td>\n",
       "      <td>0.303269</td>\n",
       "      <td>1.089680</td>\n",
       "      <td>-0.000535</td>\n",
       "      <td>0.836840</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10320</td>\n",
       "      <td>2.558219e-02</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>1055</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.020086</td>\n",
       "      <td>0.274079</td>\n",
       "      <td>-1002.464063</td>\n",
       "      <td>0.914900</td>\n",
       "      <td>0.970498</td>\n",
       "      <td>3.584998</td>\n",
       "      <td>0.738767</td>\n",
       "      <td>1.461578</td>\n",
       "      <td>-0.084745</td>\n",
       "      <td>0.640473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5338</td>\n",
       "      <td>3.449604e-01</td>\n",
       "      <td>1.017172</td>\n",
       "      <td>193</td>\n",
       "      <td>839.0</td>\n",
       "      <td>2.918547</td>\n",
       "      <td>4.042017</td>\n",
       "      <td>-785.076380</td>\n",
       "      <td>0.184470</td>\n",
       "      <td>0.839621</td>\n",
       "      <td>5.759927</td>\n",
       "      <td>-0.005959</td>\n",
       "      <td>0.878572</td>\n",
       "      <td>0.010164</td>\n",
       "      <td>0.787292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5338</td>\n",
       "      <td>1.048698e-02</td>\n",
       "      <td>7.310766</td>\n",
       "      <td>427</td>\n",
       "      <td>1113.0</td>\n",
       "      <td>0.044178</td>\n",
       "      <td>0.267781</td>\n",
       "      <td>-5588.213147</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.048596</td>\n",
       "      <td>0.007918</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.372617</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>15902</td>\n",
       "      <td>5.582507e-02</td>\n",
       "      <td>13.441752</td>\n",
       "      <td>2629</td>\n",
       "      <td>3731.0</td>\n",
       "      <td>0.251939</td>\n",
       "      <td>0.310853</td>\n",
       "      <td>-2197.909603</td>\n",
       "      <td>0.672894</td>\n",
       "      <td>0.855328</td>\n",
       "      <td>2.241832</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>0.736237</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>0.464077</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>15831</td>\n",
       "      <td>6.088005e-02</td>\n",
       "      <td>2.648969</td>\n",
       "      <td>3257</td>\n",
       "      <td>2043.0</td>\n",
       "      <td>0.851857</td>\n",
       "      <td>0.962707</td>\n",
       "      <td>-10835.318050</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.588706</td>\n",
       "      <td>1.677963</td>\n",
       "      <td>0.276500</td>\n",
       "      <td>0.418315</td>\n",
       "      <td>0.014658</td>\n",
       "      <td>0.540125</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>15902</td>\n",
       "      <td>1.233436e-01</td>\n",
       "      <td>7.070072</td>\n",
       "      <td>4441</td>\n",
       "      <td>3568.0</td>\n",
       "      <td>0.080482</td>\n",
       "      <td>1.031322</td>\n",
       "      <td>-5999.293225</td>\n",
       "      <td>0.604372</td>\n",
       "      <td>0.706529</td>\n",
       "      <td>1.830167</td>\n",
       "      <td>0.206090</td>\n",
       "      <td>0.533888</td>\n",
       "      <td>0.018533</td>\n",
       "      <td>0.664398</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15853</td>\n",
       "      <td>3.162886e-02</td>\n",
       "      <td>2.888106</td>\n",
       "      <td>4728</td>\n",
       "      <td>3385.0</td>\n",
       "      <td>0.383167</td>\n",
       "      <td>0.907307</td>\n",
       "      <td>-16591.346050</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.325795</td>\n",
       "      <td>0.327225</td>\n",
       "      <td>0.027094</td>\n",
       "      <td>0.141890</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>15833</td>\n",
       "      <td>8.301517e-02</td>\n",
       "      <td>6.088414</td>\n",
       "      <td>3698</td>\n",
       "      <td>4066.0</td>\n",
       "      <td>1.030981</td>\n",
       "      <td>0.345389</td>\n",
       "      <td>-9274.663250</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.612507</td>\n",
       "      <td>1.485216</td>\n",
       "      <td>0.136978</td>\n",
       "      <td>0.422431</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.567046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>15842</td>\n",
       "      <td>1.944422e-01</td>\n",
       "      <td>1.854693</td>\n",
       "      <td>3658</td>\n",
       "      <td>852.0</td>\n",
       "      <td>0.119293</td>\n",
       "      <td>0.264366</td>\n",
       "      <td>-7025.073078</td>\n",
       "      <td>0.241944</td>\n",
       "      <td>0.703733</td>\n",
       "      <td>2.801680</td>\n",
       "      <td>0.158624</td>\n",
       "      <td>0.587481</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.568843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>15893</td>\n",
       "      <td>1.120571e-01</td>\n",
       "      <td>1.582131</td>\n",
       "      <td>4451</td>\n",
       "      <td>799.0</td>\n",
       "      <td>0.102075</td>\n",
       "      <td>1.935693</td>\n",
       "      <td>-12537.927040</td>\n",
       "      <td>0.259797</td>\n",
       "      <td>0.546524</td>\n",
       "      <td>1.468611</td>\n",
       "      <td>0.157777</td>\n",
       "      <td>0.390697</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>0.621833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15851</td>\n",
       "      <td>3.029328e-02</td>\n",
       "      <td>14.607574</td>\n",
       "      <td>4291</td>\n",
       "      <td>5174.0</td>\n",
       "      <td>1.159809</td>\n",
       "      <td>1.199073</td>\n",
       "      <td>-17467.747490</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.272142</td>\n",
       "      <td>0.228756</td>\n",
       "      <td>0.027827</td>\n",
       "      <td>0.101376</td>\n",
       "      <td>-0.000605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15858</td>\n",
       "      <td>6.545990e-02</td>\n",
       "      <td>0.412206</td>\n",
       "      <td>6091</td>\n",
       "      <td>492.0</td>\n",
       "      <td>0.043149</td>\n",
       "      <td>0.313313</td>\n",
       "      <td>-19814.210130</td>\n",
       "      <td>0.061329</td>\n",
       "      <td>0.340403</td>\n",
       "      <td>0.668118</td>\n",
       "      <td>0.144841</td>\n",
       "      <td>0.203272</td>\n",
       "      <td>0.017479</td>\n",
       "      <td>0.723353</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>15866</td>\n",
       "      <td>4.417704e-02</td>\n",
       "      <td>1.660798</td>\n",
       "      <td>4171</td>\n",
       "      <td>1466.0</td>\n",
       "      <td>0.027115</td>\n",
       "      <td>1.794717</td>\n",
       "      <td>-1919.026104</td>\n",
       "      <td>0.690041</td>\n",
       "      <td>0.853851</td>\n",
       "      <td>1.394356</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.848264</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    series_length     stability  lumpiness  crossing_points  flat_spots  \\\n",
       "0            4032  1.050000e-62   0.000000               28       168.0   \n",
       "1            4032  0.000000e+00   0.000000               28       180.0   \n",
       "2            4032  1.280000e-05   0.000102              490       168.0   \n",
       "3            4032  5.353556e-03   0.003807             2049         4.0   \n",
       "4            4032  1.456821e-02   0.074039               50       276.0   \n",
       "5            4032  2.104731e-02   0.061766              494       168.0   \n",
       "6            4032  4.711886e-02   0.564556              481       176.0   \n",
       "7            4032  4.757963e-02   0.076025              655       456.0   \n",
       "8            4032  4.910010e-04   0.021647              167        93.0   \n",
       "9            4032  1.664999e-01   1.929794              374       212.0   \n",
       "10           4032  2.084299e-03   0.282101              572       290.0   \n",
       "11           4032  1.468810e-02   0.017492             2248         5.0   \n",
       "12           4032  5.619322e-01   0.072827             1533         9.0   \n",
       "13           4032  7.676587e-02   0.355272             1691       505.0   \n",
       "14           4034  4.826812e-01   3.619413              851       320.0   \n",
       "15           4037  8.348266e-01   0.345937             1638       456.0   \n",
       "16           4032  1.471170e-04   0.007852             2207       303.0   \n",
       "17           4032  2.957167e-02   0.348292              769       777.0   \n",
       "18           4730  1.844837e-02   1.138475              228       573.0   \n",
       "19           4032  2.948414e-02   0.802886              424       507.0   \n",
       "20           4034  1.474807e-02  13.082651              972      2387.0   \n",
       "21           4730  1.436679e-02   0.615856             2575       573.0   \n",
       "22           4040  3.687169e-02   0.068264             1730        35.0   \n",
       "23           4621  1.025456e+00   0.003169             1779       252.0   \n",
       "24           1243  1.322639e-01   3.139152              100       280.0   \n",
       "25           4033  9.581317e-01   0.116058             1370       343.0   \n",
       "26           4032  9.279393e-01   0.093072             1089       946.0   \n",
       "27           1648  1.644120e-01   0.070700              219        20.0   \n",
       "28           1648  4.131772e-02   0.054246              228        16.0   \n",
       "29           1647  7.298716e-02   0.414012              361        35.0   \n",
       "30           1647  1.435551e-01   0.272551              257        24.0   \n",
       "31           1647  2.671595e-02   1.962780              287       712.0   \n",
       "32           1647  1.118297e-02   1.921403              315       488.0   \n",
       "33           7888  6.982387e-01   0.043476              501       175.0   \n",
       "34          18050  7.755582e-02   0.233056             5441       167.0   \n",
       "35           4033  5.518243e-02   0.510129             2275        29.0   \n",
       "36          22683  7.228339e-01   0.357257              975       602.0   \n",
       "37          10320  2.558219e-02   0.013128             1055        31.0   \n",
       "38           5338  3.449604e-01   1.017172              193       839.0   \n",
       "39           5338  1.048698e-02   7.310766              427      1113.0   \n",
       "40          15902  5.582507e-02  13.441752             2629      3731.0   \n",
       "41          15831  6.088005e-02   2.648969             3257      2043.0   \n",
       "42          15902  1.233436e-01   7.070072             4441      3568.0   \n",
       "43          15853  3.162886e-02   2.888106             4728      3385.0   \n",
       "44          15833  8.301517e-02   6.088414             3698      4066.0   \n",
       "45          15842  1.944422e-01   1.854693             3658       852.0   \n",
       "46          15893  1.120571e-01   1.582131             4451       799.0   \n",
       "47          15851  3.029328e-02  14.607574             4291      5174.0   \n",
       "48          15858  6.545990e-02   0.412206             6091       492.0   \n",
       "49          15866  4.417704e-02   1.660798             4171      1466.0   \n",
       "\n",
       "    nonlinearity  unitroot_kpss   unitroot_pp   arch_lm    x_acf1   x_acf10  \\\n",
       "0       0.070376       0.046765    -45.198782  0.960470  0.989173  8.854128   \n",
       "1      -0.000293       0.043267    -63.887428  0.970557  0.985036  8.440207   \n",
       "2       2.349718       0.046790    -57.839587  0.726378  0.977531  8.643415   \n",
       "3       0.007447       0.299753  -4126.670693  0.003419 -0.009305  0.001607   \n",
       "4       0.741962       0.121571    -49.327420  0.859136  0.985528  8.769812   \n",
       "5       2.052138       0.098380    -55.541723  0.781880  0.978055  8.682667   \n",
       "6       0.039223       0.260825    -53.046075  0.922626  0.980089  8.726534   \n",
       "7       2.275400       0.185286    -52.591420  0.783589  0.979942  8.714155   \n",
       "8      -0.005879       0.008390  -4751.528222  0.298665 -0.009269  0.224518   \n",
       "9       0.164389       1.734170  -1639.435252  0.270885  0.605997  0.637076   \n",
       "10      0.066191       0.209819  -4111.795313  0.000133 -0.040142  0.002776   \n",
       "11      0.029477       2.076331  -5479.608260  0.039873 -0.117574  0.446556   \n",
       "12      0.944388      31.742803  -6910.253390  0.301557  0.303370  2.948069   \n",
       "13      0.067505       0.489215   -654.999557  0.587577  0.818554  1.326405   \n",
       "14      1.248847       1.451362    -62.565968  0.970268  0.969111  8.553823   \n",
       "15      1.939950      12.161875     -8.202838  0.996375  0.988133  9.567909   \n",
       "16      0.102933       0.045319  -4057.127914  0.000148 -0.037444  0.003042   \n",
       "17      0.217334       0.200876   -992.787092  0.366378  0.726203  0.896081   \n",
       "18      2.697196       1.035371  -3490.599993  0.078363  0.250538  0.077008   \n",
       "19      1.204699       0.374319  -3277.146318  0.095276  0.367030  0.315850   \n",
       "20      0.115234       0.781227  -4253.857995  0.096123  0.192525  0.209505   \n",
       "21      0.030949       0.287323  -5126.039828  0.043917  0.039702  0.018031   \n",
       "22      0.003772       0.624592  -4307.441063  0.030620  0.228100  0.200517   \n",
       "23      2.485430      20.719757    -12.709826  0.972019  0.987206  9.552269   \n",
       "24      0.092818       0.749119   -106.161577  0.884200  0.926089  3.152482   \n",
       "25      1.637593      21.725077    -23.910583  0.875012  0.975589  9.438414   \n",
       "26      0.863567      20.102611    -64.770967  0.398552  0.959303  8.730561   \n",
       "27      0.320453       3.322436   -291.651096  0.333751  0.844560  1.723964   \n",
       "28      0.353326       0.688890   -352.407911  0.270601  0.823062  2.040337   \n",
       "29      0.513498       0.784406   -689.702090  0.243241  0.595922  0.603031   \n",
       "30      1.757995       3.913879   -377.537596  0.098898  0.764779  1.248005   \n",
       "31      0.344567       1.727024  -1862.138673  0.003958  0.040633  0.032792   \n",
       "32      0.278744       0.181736  -1839.697103  0.005727  0.030553  0.026503   \n",
       "33      0.004126      15.832975   -157.619180  0.918206  0.977310  8.132260   \n",
       "34      1.885470       8.482093 -10076.273860  0.656113  0.434372  0.202673   \n",
       "35      0.244981       1.397734  -7018.692276  0.045816 -0.141438  0.176783   \n",
       "36      0.025294       2.419612    -85.740275  0.993368  0.996905  9.686593   \n",
       "37      0.020086       0.274079  -1002.464063  0.914900  0.970498  3.584998   \n",
       "38      2.918547       4.042017   -785.076380  0.184470  0.839621  5.759927   \n",
       "39      0.044178       0.267781  -5588.213147  0.000004  0.048596  0.007918   \n",
       "40      0.251939       0.310853  -2197.909603  0.672894  0.855328  2.241832   \n",
       "41      0.851857       0.962707 -10835.318050  0.004547  0.588706  1.677963   \n",
       "42      0.080482       1.031322  -5999.293225  0.604372  0.706529  1.830167   \n",
       "43      0.383167       0.907307 -16591.346050  0.017305  0.325795  0.327225   \n",
       "44      1.030981       0.345389  -9274.663250  0.042945  0.612507  1.485216   \n",
       "45      0.119293       0.264366  -7025.073078  0.241944  0.703733  2.801680   \n",
       "46      0.102075       1.935693 -12537.927040  0.259797  0.546524  1.468611   \n",
       "47      1.159809       1.199073 -17467.747490  0.000061  0.272142  0.228756   \n",
       "48      0.043149       0.313313 -19814.210130  0.061329  0.340403  0.668118   \n",
       "49      0.027115       1.794717  -1919.026104  0.690041  0.853851  1.394356   \n",
       "\n",
       "    seas_acf1   x_pacf5  seas_pacf     hurst  ensemble_size  \n",
       "0    0.928571  0.978583  -0.007057       NaN              1  \n",
       "1    0.928571  0.970529  -0.006061       NaN              1  \n",
       "2    0.918527  1.027842   0.205044  0.412716              2  \n",
       "3    0.005106  0.000451   0.007050  0.507001              1  \n",
       "4    0.833093  0.984697   0.138940  0.501646              1  \n",
       "5    0.861524  1.028455   0.172089  0.523080              2  \n",
       "6    0.817634  1.027627   0.142922  0.565294              1  \n",
       "7    0.796279  1.015332   0.142267  0.553390              2  \n",
       "8   -0.020033  0.001304  -0.011985  0.324410              2  \n",
       "9    0.009672  0.393273   0.017855       NaN              3  \n",
       "10   0.109389  0.002426   0.126549  0.542713              1  \n",
       "11   0.571083  0.027830   0.070232       NaN              1  \n",
       "12   0.413182  0.971923  -0.016033  1.592583              1  \n",
       "13   0.116130  0.733038   0.028988  0.950880              2  \n",
       "14   0.012096  1.036640   0.008338  1.023656              1  \n",
       "15   0.320249  1.223311   0.014974  1.089914              3  \n",
       "16   0.200400  0.002553   0.195534       NaN              1  \n",
       "17   0.084554  0.659281   0.011612  0.802616              1  \n",
       "18   0.018929  0.062992   0.017607       NaN              1  \n",
       "19   0.045452  0.160580  -0.003655       NaN              3  \n",
       "20   0.028128  0.201885   0.006898  0.997192              1  \n",
       "21   0.020649  0.010065   0.014633  0.857048              1  \n",
       "22   0.085739  0.085064  -0.000566  0.838219              1  \n",
       "23   0.638466  1.155846   0.005221  1.246498              1  \n",
       "24  -0.000728  1.031682  -0.014541  0.692340              1  \n",
       "25   0.659690  1.403919   0.063786  1.166369              1  \n",
       "26   0.628451  1.093730   0.016493  1.294494              1  \n",
       "27   0.533564  0.745947   0.015501  0.906114              1  \n",
       "28   0.601838  0.782421  -0.010624  0.720425              1  \n",
       "29   0.155811  0.379640  -0.054273  0.827410              1  \n",
       "30   0.290427  0.591957   0.009494  0.898996              1  \n",
       "31  -0.000595  0.028190  -0.011528  0.520317              1  \n",
       "32   0.000060  0.024306  -0.020632  0.390779              1  \n",
       "33   0.523375  1.052754  -0.014149  1.085836              3  \n",
       "34   0.755177  0.216052  -0.021728  0.645124              1  \n",
       "35   0.093253  0.092247   0.027901  0.994541              1  \n",
       "36   0.303269  1.089680  -0.000535  0.836840              1  \n",
       "37   0.738767  1.461578  -0.084745  0.640473              1  \n",
       "38  -0.005959  0.878572   0.010164  0.787292              1  \n",
       "39   0.001079  0.005357   0.000629  0.372617              2  \n",
       "40   0.006540  0.736237  -0.003541  0.464077              3  \n",
       "41   0.276500  0.418315   0.014658  0.540125              3  \n",
       "42   0.206090  0.533888   0.018533  0.664398              3  \n",
       "43   0.027094  0.141890  -0.007707       NaN              1  \n",
       "44   0.136978  0.422431   0.002016  0.567046              1  \n",
       "45   0.158624  0.587481   0.000580  0.568843              1  \n",
       "46   0.157777  0.390697  -0.003390  0.621833              1  \n",
       "47   0.027827  0.101376  -0.000605       NaN              3  \n",
       "48   0.144841  0.203272   0.017479  0.723353              3  \n",
       "49   0.013347  0.848264   0.012822       NaN              2  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the DataFrame\n",
    "df = ensemble_size_df[[col for col in column_mapping.values() if col in ensemble_size_df.columns]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values per column:\n",
      "series_length       0\n",
      "stability           0\n",
      "lumpiness           0\n",
      "crossing_points     0\n",
      "flat_spots          0\n",
      "nonlinearity        0\n",
      "unitroot_kpss       0\n",
      "unitroot_pp         0\n",
      "arch_lm             0\n",
      "x_acf1              0\n",
      "x_acf10             0\n",
      "seas_acf1           0\n",
      "x_pacf5             0\n",
      "seas_pacf           0\n",
      "hurst              10\n",
      "ensemble_size       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find null values in each column\n",
    "null_values_per_column = df.isnull().sum()\n",
    "\n",
    "# Print the result\n",
    "print(\"Null values per column:\")\n",
    "print(null_values_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    # Extract Y_df with the specified columns\n",
    "    Y_df = df['ensemble_size']\n",
    "    \n",
    "    # Extract X_df excluding the specified columns\n",
    "    X_df = df.drop(columns='ensemble_size')\n",
    "    \n",
    "    return X_df, Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function\n",
    "X_df, Y_df = split_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     2\n",
       "3     1\n",
       "4     1\n",
       "5     2\n",
       "6     1\n",
       "7     2\n",
       "8     2\n",
       "9     3\n",
       "10    1\n",
       "11    1\n",
       "12    1\n",
       "13    2\n",
       "14    1\n",
       "15    3\n",
       "16    1\n",
       "17    1\n",
       "18    1\n",
       "19    3\n",
       "20    1\n",
       "21    1\n",
       "22    1\n",
       "23    1\n",
       "24    1\n",
       "25    1\n",
       "26    1\n",
       "27    1\n",
       "28    1\n",
       "29    1\n",
       "30    1\n",
       "31    1\n",
       "32    1\n",
       "33    3\n",
       "34    1\n",
       "35    1\n",
       "36    1\n",
       "37    1\n",
       "38    1\n",
       "39    2\n",
       "40    3\n",
       "41    3\n",
       "42    3\n",
       "43    1\n",
       "44    1\n",
       "45    1\n",
       "46    1\n",
       "47    3\n",
       "48    3\n",
       "49    2\n",
       "Name: ensemble_size, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame\n",
    "X_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_out_of_range_columns(df):\n",
    "    # Initialize the MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    \n",
    "    # Identify columns with values outside the range [0, 1]\n",
    "    cols_to_scale = df.columns[(df.min() < 0) | (df.max() > 1)]\n",
    "    \n",
    "    # Scale the identified columns\n",
    "    df[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_length</th>\n",
       "      <th>stability</th>\n",
       "      <th>lumpiness</th>\n",
       "      <th>crossing_points</th>\n",
       "      <th>flat_spots</th>\n",
       "      <th>nonlinearity</th>\n",
       "      <th>unitroot_kpss</th>\n",
       "      <th>unitroot_pp</th>\n",
       "      <th>arch_lm</th>\n",
       "      <th>x_acf1</th>\n",
       "      <th>x_acf10</th>\n",
       "      <th>seas_acf1</th>\n",
       "      <th>x_pacf5</th>\n",
       "      <th>seas_pacf</th>\n",
       "      <th>hurst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>1.023935e-62</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>0.026075</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.998132</td>\n",
       "      <td>0.960470</td>\n",
       "      <td>0.993207</td>\n",
       "      <td>0.914046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669437</td>\n",
       "      <td>0.268085</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.001910</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.997188</td>\n",
       "      <td>0.970557</td>\n",
       "      <td>0.989574</td>\n",
       "      <td>0.871307</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.663925</td>\n",
       "      <td>0.271520</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>1.248225e-05</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.076200</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>0.805490</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.726378</td>\n",
       "      <td>0.982980</td>\n",
       "      <td>0.892289</td>\n",
       "      <td>0.989411</td>\n",
       "      <td>0.703150</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.259149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>5.220660e-03</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.009181</td>\n",
       "      <td>0.792060</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.116074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.316763</td>\n",
       "      <td>0.318351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>1.420657e-02</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.003629</td>\n",
       "      <td>0.052611</td>\n",
       "      <td>0.255722</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.997924</td>\n",
       "      <td>0.859136</td>\n",
       "      <td>0.990005</td>\n",
       "      <td>0.905340</td>\n",
       "      <td>0.899349</td>\n",
       "      <td>0.673621</td>\n",
       "      <td>0.771888</td>\n",
       "      <td>0.314989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>2.052484e-02</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.076860</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>0.703734</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.997610</td>\n",
       "      <td>0.781880</td>\n",
       "      <td>0.983441</td>\n",
       "      <td>0.896342</td>\n",
       "      <td>0.929320</td>\n",
       "      <td>0.703569</td>\n",
       "      <td>0.886278</td>\n",
       "      <td>0.328447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>4.594918e-02</td>\n",
       "      <td>0.038648</td>\n",
       "      <td>0.074715</td>\n",
       "      <td>0.033269</td>\n",
       "      <td>0.015422</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>0.997736</td>\n",
       "      <td>0.922626</td>\n",
       "      <td>0.985227</td>\n",
       "      <td>0.900871</td>\n",
       "      <td>0.883052</td>\n",
       "      <td>0.703002</td>\n",
       "      <td>0.785628</td>\n",
       "      <td>0.354954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>4.639852e-02</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.103414</td>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.780077</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.997759</td>\n",
       "      <td>0.783589</td>\n",
       "      <td>0.985099</td>\n",
       "      <td>0.899593</td>\n",
       "      <td>0.860540</td>\n",
       "      <td>0.694588</td>\n",
       "      <td>0.783368</td>\n",
       "      <td>0.347480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>4.788124e-04</td>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.017215</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760511</td>\n",
       "      <td>0.298665</td>\n",
       "      <td>0.116106</td>\n",
       "      <td>0.023016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.251077</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>1.623667e-01</td>\n",
       "      <td>0.132109</td>\n",
       "      <td>0.057067</td>\n",
       "      <td>0.040232</td>\n",
       "      <td>0.058223</td>\n",
       "      <td>0.054382</td>\n",
       "      <td>0.917640</td>\n",
       "      <td>0.270885</td>\n",
       "      <td>0.656599</td>\n",
       "      <td>0.065614</td>\n",
       "      <td>0.031315</td>\n",
       "      <td>0.268849</td>\n",
       "      <td>0.354050</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>2.032559e-03</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.089725</td>\n",
       "      <td>0.055319</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.006347</td>\n",
       "      <td>0.792811</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.088985</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.136434</td>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.729128</td>\n",
       "      <td>0.340775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>1.432349e-02</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.366155</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.012090</td>\n",
       "      <td>0.065164</td>\n",
       "      <td>0.723750</td>\n",
       "      <td>0.039873</td>\n",
       "      <td>0.020963</td>\n",
       "      <td>0.045942</td>\n",
       "      <td>0.623143</td>\n",
       "      <td>0.018738</td>\n",
       "      <td>0.534792</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>5.479829e-01</td>\n",
       "      <td>0.004986</td>\n",
       "      <td>0.248227</td>\n",
       "      <td>0.000967</td>\n",
       "      <td>0.324941</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.651517</td>\n",
       "      <td>0.301557</td>\n",
       "      <td>0.390750</td>\n",
       "      <td>0.304230</td>\n",
       "      <td>0.456687</td>\n",
       "      <td>0.664879</td>\n",
       "      <td>0.237110</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>7.486024e-02</td>\n",
       "      <td>0.024321</td>\n",
       "      <td>0.274287</td>\n",
       "      <td>0.096905</td>\n",
       "      <td>0.025093</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.967343</td>\n",
       "      <td>0.587577</td>\n",
       "      <td>0.843324</td>\n",
       "      <td>0.136789</td>\n",
       "      <td>0.143541</td>\n",
       "      <td>0.501385</td>\n",
       "      <td>0.392467</td>\n",
       "      <td>0.597068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.130177</td>\n",
       "      <td>4.706991e-01</td>\n",
       "      <td>0.247776</td>\n",
       "      <td>0.135741</td>\n",
       "      <td>0.061122</td>\n",
       "      <td>0.429050</td>\n",
       "      <td>0.045470</td>\n",
       "      <td>0.997255</td>\n",
       "      <td>0.970268</td>\n",
       "      <td>0.975584</td>\n",
       "      <td>0.883039</td>\n",
       "      <td>0.033870</td>\n",
       "      <td>0.709171</td>\n",
       "      <td>0.321210</td>\n",
       "      <td>0.642765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.130317</td>\n",
       "      <td>8.141029e-01</td>\n",
       "      <td>0.023682</td>\n",
       "      <td>0.265545</td>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.665371</td>\n",
       "      <td>0.382975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996375</td>\n",
       "      <td>0.992294</td>\n",
       "      <td>0.987746</td>\n",
       "      <td>0.358719</td>\n",
       "      <td>0.836929</td>\n",
       "      <td>0.344107</td>\n",
       "      <td>0.684369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>1.434650e-04</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.359393</td>\n",
       "      <td>0.057834</td>\n",
       "      <td>0.037208</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.795571</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.091355</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.232377</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.967181</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>2.883758e-02</td>\n",
       "      <td>0.023843</td>\n",
       "      <td>0.122217</td>\n",
       "      <td>0.149516</td>\n",
       "      <td>0.076327</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.950289</td>\n",
       "      <td>0.366378</td>\n",
       "      <td>0.762196</td>\n",
       "      <td>0.092357</td>\n",
       "      <td>0.110254</td>\n",
       "      <td>0.450905</td>\n",
       "      <td>0.332508</td>\n",
       "      <td>0.503971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.162640</td>\n",
       "      <td>1.799041e-02</td>\n",
       "      <td>0.077937</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>0.924309</td>\n",
       "      <td>0.032362</td>\n",
       "      <td>0.824175</td>\n",
       "      <td>0.078363</td>\n",
       "      <td>0.344339</td>\n",
       "      <td>0.007785</td>\n",
       "      <td>0.041073</td>\n",
       "      <td>0.042803</td>\n",
       "      <td>0.353194</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>2.875223e-02</td>\n",
       "      <td>0.054964</td>\n",
       "      <td>0.065314</td>\n",
       "      <td>0.097292</td>\n",
       "      <td>0.413954</td>\n",
       "      <td>0.011531</td>\n",
       "      <td>0.834952</td>\n",
       "      <td>0.095276</td>\n",
       "      <td>0.446674</td>\n",
       "      <td>0.032446</td>\n",
       "      <td>0.069033</td>\n",
       "      <td>0.109593</td>\n",
       "      <td>0.279824</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.130177</td>\n",
       "      <td>1.438196e-02</td>\n",
       "      <td>0.895607</td>\n",
       "      <td>0.155698</td>\n",
       "      <td>0.460928</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>0.785638</td>\n",
       "      <td>0.096123</td>\n",
       "      <td>0.293376</td>\n",
       "      <td>0.021466</td>\n",
       "      <td>0.050771</td>\n",
       "      <td>0.137862</td>\n",
       "      <td>0.316238</td>\n",
       "      <td>0.626148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.162640</td>\n",
       "      <td>1.401015e-02</td>\n",
       "      <td>0.042160</td>\n",
       "      <td>0.420089</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>0.741602</td>\n",
       "      <td>0.043917</td>\n",
       "      <td>0.159126</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.042886</td>\n",
       "      <td>0.006580</td>\n",
       "      <td>0.342932</td>\n",
       "      <td>0.538150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.130457</td>\n",
       "      <td>3.595639e-02</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.280719</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.782933</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>0.324628</td>\n",
       "      <td>0.020538</td>\n",
       "      <td>0.111503</td>\n",
       "      <td>0.057910</td>\n",
       "      <td>0.290481</td>\n",
       "      <td>0.526327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.157556</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.288801</td>\n",
       "      <td>0.047969</td>\n",
       "      <td>0.851897</td>\n",
       "      <td>0.652647</td>\n",
       "      <td>0.999772</td>\n",
       "      <td>0.972019</td>\n",
       "      <td>0.991479</td>\n",
       "      <td>0.986131</td>\n",
       "      <td>0.694177</td>\n",
       "      <td>0.790756</td>\n",
       "      <td>0.310453</td>\n",
       "      <td>0.782689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.289806e-01</td>\n",
       "      <td>0.214899</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.053385</td>\n",
       "      <td>0.033749</td>\n",
       "      <td>0.023341</td>\n",
       "      <td>0.995054</td>\n",
       "      <td>0.884200</td>\n",
       "      <td>0.937790</td>\n",
       "      <td>0.325336</td>\n",
       "      <td>0.020351</td>\n",
       "      <td>0.705778</td>\n",
       "      <td>0.242259</td>\n",
       "      <td>0.434728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.130131</td>\n",
       "      <td>9.343472e-01</td>\n",
       "      <td>0.007945</td>\n",
       "      <td>0.221343</td>\n",
       "      <td>0.065571</td>\n",
       "      <td>0.561981</td>\n",
       "      <td>0.684326</td>\n",
       "      <td>0.999207</td>\n",
       "      <td>0.875012</td>\n",
       "      <td>0.981275</td>\n",
       "      <td>0.974375</td>\n",
       "      <td>0.716551</td>\n",
       "      <td>0.960538</td>\n",
       "      <td>0.512548</td>\n",
       "      <td>0.732376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.130084</td>\n",
       "      <td>9.049042e-01</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>0.174996</td>\n",
       "      <td>0.182205</td>\n",
       "      <td>0.297305</td>\n",
       "      <td>0.633200</td>\n",
       "      <td>0.997144</td>\n",
       "      <td>0.398552</td>\n",
       "      <td>0.966968</td>\n",
       "      <td>0.901287</td>\n",
       "      <td>0.683619</td>\n",
       "      <td>0.748243</td>\n",
       "      <td>0.349350</td>\n",
       "      <td>0.812827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.018890</td>\n",
       "      <td>1.603307e-01</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>0.031503</td>\n",
       "      <td>0.003095</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.104431</td>\n",
       "      <td>0.985689</td>\n",
       "      <td>0.333751</td>\n",
       "      <td>0.866169</td>\n",
       "      <td>0.177838</td>\n",
       "      <td>0.583591</td>\n",
       "      <td>0.510220</td>\n",
       "      <td>0.345926</td>\n",
       "      <td>0.568959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.018890</td>\n",
       "      <td>4.029205e-02</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.032987</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.122829</td>\n",
       "      <td>0.021444</td>\n",
       "      <td>0.982621</td>\n",
       "      <td>0.270601</td>\n",
       "      <td>0.847284</td>\n",
       "      <td>0.210504</td>\n",
       "      <td>0.655564</td>\n",
       "      <td>0.535183</td>\n",
       "      <td>0.255774</td>\n",
       "      <td>0.452363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>7.117533e-02</td>\n",
       "      <td>0.028342</td>\n",
       "      <td>0.054923</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>0.024453</td>\n",
       "      <td>0.965591</td>\n",
       "      <td>0.243241</td>\n",
       "      <td>0.647748</td>\n",
       "      <td>0.062099</td>\n",
       "      <td>0.185371</td>\n",
       "      <td>0.259518</td>\n",
       "      <td>0.105150</td>\n",
       "      <td>0.519539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>1.399915e-01</td>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.037770</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.603152</td>\n",
       "      <td>0.123068</td>\n",
       "      <td>0.981352</td>\n",
       "      <td>0.098898</td>\n",
       "      <td>0.796084</td>\n",
       "      <td>0.128694</td>\n",
       "      <td>0.327281</td>\n",
       "      <td>0.404829</td>\n",
       "      <td>0.325199</td>\n",
       "      <td>0.564489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>2.605276e-02</td>\n",
       "      <td>0.134367</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.136944</td>\n",
       "      <td>0.119834</td>\n",
       "      <td>0.054157</td>\n",
       "      <td>0.906395</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.159943</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.020492</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.252655</td>\n",
       "      <td>0.326713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.018843</td>\n",
       "      <td>1.090536e-02</td>\n",
       "      <td>0.131535</td>\n",
       "      <td>0.047336</td>\n",
       "      <td>0.093617</td>\n",
       "      <td>0.097326</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.907528</td>\n",
       "      <td>0.005727</td>\n",
       "      <td>0.151089</td>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.021182</td>\n",
       "      <td>0.016326</td>\n",
       "      <td>0.221240</td>\n",
       "      <td>0.245375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.309935</td>\n",
       "      <td>6.809057e-01</td>\n",
       "      <td>0.002976</td>\n",
       "      <td>0.078014</td>\n",
       "      <td>0.033075</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.498657</td>\n",
       "      <td>0.992456</td>\n",
       "      <td>0.918206</td>\n",
       "      <td>0.982787</td>\n",
       "      <td>0.839511</td>\n",
       "      <td>0.572850</td>\n",
       "      <td>0.720199</td>\n",
       "      <td>0.243609</td>\n",
       "      <td>0.681808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.783909</td>\n",
       "      <td>7.563058e-02</td>\n",
       "      <td>0.015954</td>\n",
       "      <td>0.892792</td>\n",
       "      <td>0.031528</td>\n",
       "      <td>0.646742</td>\n",
       "      <td>0.267019</td>\n",
       "      <td>0.491666</td>\n",
       "      <td>0.656113</td>\n",
       "      <td>0.505831</td>\n",
       "      <td>0.020761</td>\n",
       "      <td>0.817211</td>\n",
       "      <td>0.147558</td>\n",
       "      <td>0.217459</td>\n",
       "      <td>0.405080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.130131</td>\n",
       "      <td>5.381258e-02</td>\n",
       "      <td>0.034922</td>\n",
       "      <td>0.370609</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.085781</td>\n",
       "      <td>0.043780</td>\n",
       "      <td>0.646042</td>\n",
       "      <td>0.045816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018087</td>\n",
       "      <td>0.119424</td>\n",
       "      <td>0.062825</td>\n",
       "      <td>0.388718</td>\n",
       "      <td>0.624483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.048904e-01</td>\n",
       "      <td>0.024457</td>\n",
       "      <td>0.156193</td>\n",
       "      <td>0.115667</td>\n",
       "      <td>0.010660</td>\n",
       "      <td>0.075981</td>\n",
       "      <td>0.996085</td>\n",
       "      <td>0.993368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.340819</td>\n",
       "      <td>0.745472</td>\n",
       "      <td>0.290591</td>\n",
       "      <td>0.525461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.423368</td>\n",
       "      <td>2.494714e-02</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.169388</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.008879</td>\n",
       "      <td>0.008372</td>\n",
       "      <td>0.949800</td>\n",
       "      <td>0.914900</td>\n",
       "      <td>0.976802</td>\n",
       "      <td>0.369994</td>\n",
       "      <td>0.799912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.190998</td>\n",
       "      <td>3.363971e-01</td>\n",
       "      <td>0.069633</td>\n",
       "      <td>0.027214</td>\n",
       "      <td>0.161509</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.960776</td>\n",
       "      <td>0.184470</td>\n",
       "      <td>0.861831</td>\n",
       "      <td>0.594562</td>\n",
       "      <td>0.014837</td>\n",
       "      <td>0.600989</td>\n",
       "      <td>0.327512</td>\n",
       "      <td>0.494349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.190998</td>\n",
       "      <td>1.022665e-02</td>\n",
       "      <td>0.500478</td>\n",
       "      <td>0.065809</td>\n",
       "      <td>0.214507</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>0.008174</td>\n",
       "      <td>0.718267</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.166939</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.022256</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.294607</td>\n",
       "      <td>0.233970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.683722</td>\n",
       "      <td>5.443927e-02</td>\n",
       "      <td>0.920191</td>\n",
       "      <td>0.428996</td>\n",
       "      <td>0.720890</td>\n",
       "      <td>0.088160</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.889442</td>\n",
       "      <td>0.672894</td>\n",
       "      <td>0.875629</td>\n",
       "      <td>0.231309</td>\n",
       "      <td>0.028013</td>\n",
       "      <td>0.503574</td>\n",
       "      <td>0.280217</td>\n",
       "      <td>0.291399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.680410</td>\n",
       "      <td>5.936877e-02</td>\n",
       "      <td>0.181342</td>\n",
       "      <td>0.532575</td>\n",
       "      <td>0.394391</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.030072</td>\n",
       "      <td>0.453342</td>\n",
       "      <td>0.004547</td>\n",
       "      <td>0.641409</td>\n",
       "      <td>0.173088</td>\n",
       "      <td>0.312600</td>\n",
       "      <td>0.285987</td>\n",
       "      <td>0.343017</td>\n",
       "      <td>0.339150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.683722</td>\n",
       "      <td>1.202817e-01</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.727857</td>\n",
       "      <td>0.689362</td>\n",
       "      <td>0.029531</td>\n",
       "      <td>0.032234</td>\n",
       "      <td>0.697511</td>\n",
       "      <td>0.604372</td>\n",
       "      <td>0.744914</td>\n",
       "      <td>0.188804</td>\n",
       "      <td>0.238374</td>\n",
       "      <td>0.365086</td>\n",
       "      <td>0.356390</td>\n",
       "      <td>0.417182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.681437</td>\n",
       "      <td>3.084371e-02</td>\n",
       "      <td>0.197713</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.653965</td>\n",
       "      <td>0.133033</td>\n",
       "      <td>0.028326</td>\n",
       "      <td>0.162722</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>0.410450</td>\n",
       "      <td>0.033621</td>\n",
       "      <td>0.049681</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.265840</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.680504</td>\n",
       "      <td>8.095440e-02</td>\n",
       "      <td>0.416798</td>\n",
       "      <td>0.605311</td>\n",
       "      <td>0.785687</td>\n",
       "      <td>0.354551</td>\n",
       "      <td>0.010619</td>\n",
       "      <td>0.532139</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.662318</td>\n",
       "      <td>0.153187</td>\n",
       "      <td>0.165518</td>\n",
       "      <td>0.288805</td>\n",
       "      <td>0.299392</td>\n",
       "      <td>0.356054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.680924</td>\n",
       "      <td>1.896154e-01</td>\n",
       "      <td>0.126968</td>\n",
       "      <td>0.598714</td>\n",
       "      <td>0.164023</td>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.645720</td>\n",
       "      <td>0.241944</td>\n",
       "      <td>0.742457</td>\n",
       "      <td>0.289115</td>\n",
       "      <td>0.188337</td>\n",
       "      <td>0.401765</td>\n",
       "      <td>0.294439</td>\n",
       "      <td>0.357182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.683302</td>\n",
       "      <td>1.092755e-01</td>\n",
       "      <td>0.108309</td>\n",
       "      <td>0.729507</td>\n",
       "      <td>0.153772</td>\n",
       "      <td>0.036915</td>\n",
       "      <td>0.060732</td>\n",
       "      <td>0.367378</td>\n",
       "      <td>0.259797</td>\n",
       "      <td>0.604353</td>\n",
       "      <td>0.151472</td>\n",
       "      <td>0.187444</td>\n",
       "      <td>0.267086</td>\n",
       "      <td>0.280737</td>\n",
       "      <td>0.390456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.681343</td>\n",
       "      <td>2.954128e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703117</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.398604</td>\n",
       "      <td>0.037520</td>\n",
       "      <td>0.118472</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.363317</td>\n",
       "      <td>0.023454</td>\n",
       "      <td>0.050454</td>\n",
       "      <td>0.069074</td>\n",
       "      <td>0.290349</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.681670</td>\n",
       "      <td>6.383493e-02</td>\n",
       "      <td>0.028219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.094391</td>\n",
       "      <td>0.016765</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061329</td>\n",
       "      <td>0.423283</td>\n",
       "      <td>0.068819</td>\n",
       "      <td>0.173807</td>\n",
       "      <td>0.138812</td>\n",
       "      <td>0.352753</td>\n",
       "      <td>0.454201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.682043</td>\n",
       "      <td>4.308039e-02</td>\n",
       "      <td>0.113694</td>\n",
       "      <td>0.683325</td>\n",
       "      <td>0.282785</td>\n",
       "      <td>0.011282</td>\n",
       "      <td>0.056290</td>\n",
       "      <td>0.903523</td>\n",
       "      <td>0.690041</td>\n",
       "      <td>0.874331</td>\n",
       "      <td>0.143805</td>\n",
       "      <td>0.035189</td>\n",
       "      <td>0.580246</td>\n",
       "      <td>0.336683</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    series_length     stability  lumpiness  crossing_points  flat_spots  \\\n",
       "0        0.130084  1.023935e-62   0.000000         0.000000    0.031721   \n",
       "1        0.130084  0.000000e+00   0.000000         0.000000    0.034043   \n",
       "2        0.130084  1.248225e-05   0.000007         0.076200    0.031721   \n",
       "3        0.130084  5.220660e-03   0.000261         0.333333    0.000000   \n",
       "4        0.130084  1.420657e-02   0.005069         0.003629    0.052611   \n",
       "5        0.130084  2.052484e-02   0.004228         0.076860    0.031721   \n",
       "6        0.130084  4.594918e-02   0.038648         0.074715    0.033269   \n",
       "7        0.130084  4.639852e-02   0.005204         0.103414    0.087427   \n",
       "8        0.130084  4.788124e-04   0.001482         0.022926    0.017215   \n",
       "9        0.130084  1.623667e-01   0.132109         0.057067    0.040232   \n",
       "10       0.130084  2.032559e-03   0.019312         0.089725    0.055319   \n",
       "11       0.130084  1.432349e-02   0.001197         0.366155    0.000193   \n",
       "12       0.130084  5.479829e-01   0.004986         0.248227    0.000967   \n",
       "13       0.130084  7.486024e-02   0.024321         0.274287    0.096905   \n",
       "14       0.130177  4.706991e-01   0.247776         0.135741    0.061122   \n",
       "15       0.130317  8.141029e-01   0.023682         0.265545    0.087427   \n",
       "16       0.130084  1.434650e-04   0.000538         0.359393    0.057834   \n",
       "17       0.130084  2.883758e-02   0.023843         0.122217    0.149516   \n",
       "18       0.162640  1.799041e-02   0.077937         0.032987    0.110058   \n",
       "19       0.130084  2.875223e-02   0.054964         0.065314    0.097292   \n",
       "20       0.130177  1.438196e-02   0.895607         0.155698    0.460928   \n",
       "21       0.162640  1.401015e-02   0.042160         0.420089    0.110058   \n",
       "22       0.130457  3.595639e-02   0.004673         0.280719    0.005996   \n",
       "23       0.157556  1.000000e+00   0.000217         0.288801    0.047969   \n",
       "24       0.000000  1.289806e-01   0.214899         0.011875    0.053385   \n",
       "25       0.130131  9.343472e-01   0.007945         0.221343    0.065571   \n",
       "26       0.130084  9.049042e-01   0.006372         0.174996    0.182205   \n",
       "27       0.018890  1.603307e-01   0.004840         0.031503    0.003095   \n",
       "28       0.018890  4.029205e-02   0.003714         0.032987    0.002321   \n",
       "29       0.018843  7.117533e-02   0.028342         0.054923    0.005996   \n",
       "30       0.018843  1.399915e-01   0.018658         0.037770    0.003868   \n",
       "31       0.018843  2.605276e-02   0.134367         0.042718    0.136944   \n",
       "32       0.018843  1.090536e-02   0.131535         0.047336    0.093617   \n",
       "33       0.309935  6.809057e-01   0.002976         0.078014    0.033075   \n",
       "34       0.783909  7.563058e-02   0.015954         0.892792    0.031528   \n",
       "35       0.130131  5.381258e-02   0.034922         0.370609    0.004836   \n",
       "36       1.000000  7.048904e-01   0.024457         0.156193    0.115667   \n",
       "37       0.423368  2.494714e-02   0.000899         0.169388    0.005222   \n",
       "38       0.190998  3.363971e-01   0.069633         0.027214    0.161509   \n",
       "39       0.190998  1.022665e-02   0.500478         0.065809    0.214507   \n",
       "40       0.683722  5.443927e-02   0.920191         0.428996    0.720890   \n",
       "41       0.680410  5.936877e-02   0.181342         0.532575    0.394391   \n",
       "42       0.683722  1.202817e-01   0.484000         0.727857    0.689362   \n",
       "43       0.681437  3.084371e-02   0.197713         0.775194    0.653965   \n",
       "44       0.680504  8.095440e-02   0.416798         0.605311    0.785687   \n",
       "45       0.680924  1.896154e-01   0.126968         0.598714    0.164023   \n",
       "46       0.683302  1.092755e-01   0.108309         0.729507    0.153772   \n",
       "47       0.681343  2.954128e-02   1.000000         0.703117    1.000000   \n",
       "48       0.681670  6.383493e-02   0.028219         1.000000    0.094391   \n",
       "49       0.682043  4.308039e-02   0.113694         0.683325    0.282785   \n",
       "\n",
       "    nonlinearity  unitroot_kpss  unitroot_pp   arch_lm    x_acf1   x_acf10  \\\n",
       "0       0.026075       0.001209     0.998132  0.960470  0.993207  0.914046   \n",
       "1       0.001910       0.001099     0.997188  0.970557  0.989574  0.871307   \n",
       "2       0.805490       0.001210     0.997494  0.726378  0.982980  0.892289   \n",
       "3       0.004557       0.009181     0.792060  0.003419  0.116074  0.000000   \n",
       "4       0.255722       0.003566     0.997924  0.859136  0.990005  0.905340   \n",
       "5       0.703734       0.002836     0.997610  0.781880  0.983441  0.896342   \n",
       "6       0.015422       0.007955     0.997736  0.922626  0.985227  0.900871   \n",
       "7       0.780077       0.005574     0.997759  0.783589  0.985099  0.899593   \n",
       "8       0.000000       0.000000     0.760511  0.298665  0.116106  0.023016   \n",
       "9       0.058223       0.054382     0.917640  0.270885  0.656599  0.065614   \n",
       "10      0.024644       0.006347     0.792811  0.000133  0.088985  0.000121   \n",
       "11      0.012090       0.065164     0.723750  0.039873  0.020963  0.045942   \n",
       "12      0.324941       1.000000     0.651517  0.301557  0.390750  0.304230   \n",
       "13      0.025093       0.015152     0.967343  0.587577  0.843324  0.136789   \n",
       "14      0.429050       0.045470     0.997255  0.970268  0.975584  0.883039   \n",
       "15      0.665371       0.382975     1.000000  0.996375  0.992294  0.987746   \n",
       "16      0.037208       0.001164     0.795571  0.000148  0.091355  0.000148   \n",
       "17      0.076327       0.006066     0.950289  0.366378  0.762196  0.092357   \n",
       "18      0.924309       0.032362     0.824175  0.078363  0.344339  0.007785   \n",
       "19      0.413954       0.011531     0.834952  0.095276  0.446674  0.032446   \n",
       "20      0.041414       0.024353     0.785638  0.096123  0.293376  0.021466   \n",
       "21      0.012593       0.008790     0.741602  0.043917  0.159126  0.001696   \n",
       "22      0.003300       0.019417     0.782933  0.030620  0.324628  0.020538   \n",
       "23      0.851897       0.652647     0.999772  0.972019  0.991479  0.986131   \n",
       "24      0.033749       0.023341     0.995054  0.884200  0.937790  0.325336   \n",
       "25      0.561981       0.684326     0.999207  0.875012  0.981275  0.974375   \n",
       "26      0.297305       0.633200     0.997144  0.398552  0.966968  0.901287   \n",
       "27      0.111588       0.104431     0.985689  0.333751  0.866169  0.177838   \n",
       "28      0.122829       0.021444     0.982621  0.270601  0.847284  0.210504   \n",
       "29      0.177600       0.024453     0.965591  0.243241  0.647748  0.062099   \n",
       "30      0.603152       0.123068     0.981352  0.098898  0.796084  0.128694   \n",
       "31      0.119834       0.054157     0.906395  0.003958  0.159943  0.003220   \n",
       "32      0.097326       0.005462     0.907528  0.005727  0.151089  0.002571   \n",
       "33      0.003421       0.498657     0.992456  0.918206  0.982787  0.839511   \n",
       "34      0.646742       0.267019     0.491666  0.656113  0.505831  0.020761   \n",
       "35      0.085781       0.043780     0.646042  0.045816  0.000000  0.018087   \n",
       "36      0.010660       0.075981     0.996085  0.993368  1.000000  1.000000   \n",
       "37      0.008879       0.008372     0.949800  0.914900  0.976802  0.369994   \n",
       "38      1.000000       0.127106     0.960776  0.184470  0.861831  0.594562   \n",
       "39      0.017117       0.008174     0.718267  0.000004  0.166939  0.000652   \n",
       "40      0.088160       0.009531     0.889442  0.672894  0.875629  0.231309   \n",
       "41      0.293300       0.030072     0.453342  0.004547  0.641409  0.173088   \n",
       "42      0.029531       0.032234     0.697511  0.604372  0.744914  0.188804   \n",
       "43      0.133033       0.028326     0.162722  0.017305  0.410450  0.033621   \n",
       "44      0.354551       0.010619     0.532139  0.042945  0.662318  0.153187   \n",
       "45      0.042802       0.008066     0.645720  0.241944  0.742457  0.289115   \n",
       "46      0.036915       0.060732     0.367378  0.259797  0.604353  0.151472   \n",
       "47      0.398604       0.037520     0.118472  0.000061  0.363317  0.023454   \n",
       "48      0.016765       0.009609     0.000000  0.061329  0.423283  0.068819   \n",
       "49      0.011282       0.056290     0.903523  0.690041  0.874331  0.143805   \n",
       "\n",
       "    seas_acf1   x_pacf5  seas_pacf     hurst  \n",
       "0    1.000000  0.669437   0.268085  0.000000  \n",
       "1    1.000000  0.663925   0.271520  0.000000  \n",
       "2    0.989411  0.703150   1.000000  0.259149  \n",
       "3    0.026501  0.000000   0.316763  0.318351  \n",
       "4    0.899349  0.673621   0.771888  0.314989  \n",
       "5    0.929320  0.703569   0.886278  0.328447  \n",
       "6    0.883052  0.703002   0.785628  0.354954  \n",
       "7    0.860540  0.694588   0.783368  0.347480  \n",
       "8    0.000000  0.000584   0.251077  0.203700  \n",
       "9    0.031315  0.268849   0.354050  0.000000  \n",
       "10   0.136434  0.001352   0.729128  0.340775  \n",
       "11   0.623143  0.018738   0.534792  0.000000  \n",
       "12   0.456687  0.664879   0.237110  1.000000  \n",
       "13   0.143541  0.501385   0.392467  0.597068  \n",
       "14   0.033870  0.709171   0.321210  0.642765  \n",
       "15   0.358719  0.836929   0.344107  0.684369  \n",
       "16   0.232377  0.001439   0.967181  0.000000  \n",
       "17   0.110254  0.450905   0.332508  0.503971  \n",
       "18   0.041073  0.042803   0.353194  0.000000  \n",
       "19   0.069033  0.109593   0.279824  0.000000  \n",
       "20   0.050771  0.137862   0.316238  0.626148  \n",
       "21   0.042886  0.006580   0.342932  0.538150  \n",
       "22   0.111503  0.057910   0.290481  0.526327  \n",
       "23   0.694177  0.790756   0.310453  0.782689  \n",
       "24   0.020351  0.705778   0.242259  0.434728  \n",
       "25   0.716551  0.960538   0.512548  0.732376  \n",
       "26   0.683619  0.748243   0.349350  0.812827  \n",
       "27   0.583591  0.510220   0.345926  0.568959  \n",
       "28   0.655564  0.535183   0.255774  0.452363  \n",
       "29   0.185371  0.259518   0.105150  0.519539  \n",
       "30   0.327281  0.404829   0.325199  0.564489  \n",
       "31   0.020492  0.018985   0.252655  0.326713  \n",
       "32   0.021182  0.016326   0.221240  0.245375  \n",
       "33   0.572850  0.720199   0.243609  0.681808  \n",
       "34   0.817211  0.147558   0.217459  0.405080  \n",
       "35   0.119424  0.062825   0.388718  0.624483  \n",
       "36   0.340819  0.745472   0.290591  0.525461  \n",
       "37   0.799912  1.000000   0.000000  0.402160  \n",
       "38   0.014837  0.600989   0.327512  0.494349  \n",
       "39   0.022256  0.003358   0.294607  0.233970  \n",
       "40   0.028013  0.503574   0.280217  0.291399  \n",
       "41   0.312600  0.285987   0.343017  0.339150  \n",
       "42   0.238374  0.365086   0.356390  0.417182  \n",
       "43   0.049681  0.096801   0.265840  0.000000  \n",
       "44   0.165518  0.288805   0.299392  0.356054  \n",
       "45   0.188337  0.401765   0.294439  0.357182  \n",
       "46   0.187444  0.267086   0.280737  0.390456  \n",
       "47   0.050454  0.069074   0.290349  0.000000  \n",
       "48   0.173807  0.138812   0.352753  0.454201  \n",
       "49   0.035189  0.580246   0.336683  0.000000  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_scaled = scale_out_of_range_columns(X_df)\n",
    "\n",
    "X_df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 15)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit PCA\n",
    "pca = PCA().fit(X_df_scaled)\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Plot the cumulative explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.title('Explained Variance by Components')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to cover around 90% of the variance: 9\n"
     ]
    }
   ],
   "source": [
    "# Find the number of components that cover around 90% of the variance\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f'Number of components to cover around 90% of the variance: {n_components}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1         2         3         4         5         6  \\\n",
      "0  0.940889 -0.181963 -0.716503  0.123161 -0.182026  0.092684 -0.056400   \n",
      "1  0.917970 -0.184337 -0.722219  0.142343 -0.199293  0.094129 -0.066682   \n",
      "2  1.014027 -0.258317 -0.520348 -0.652627  0.281745  0.045885  0.003059   \n",
      "3 -0.857151 -0.381727  0.107079  0.038964 -0.189092 -0.020549  0.141581   \n",
      "4  0.964053 -0.231758 -0.553620 -0.145307 -0.003880  0.187115  0.031966   \n",
      "5  1.012002 -0.226206 -0.464880 -0.502912  0.221470  0.042031 -0.002662   \n",
      "6  0.960155 -0.181190 -0.573279  0.015770 -0.159379  0.289216  0.069565   \n",
      "7  0.992727 -0.169214 -0.386846 -0.486289  0.286577 -0.022725 -0.013688   \n",
      "8 -0.712337 -0.458905 -0.004523  0.200858 -0.098861 -0.036217  0.220733   \n",
      "9 -0.342693 -0.291803 -0.100699  0.275114  0.124900 -0.136262  0.146778   \n",
      "\n",
      "          7         8  \n",
      "0  0.358450 -0.077170  \n",
      "1  0.356212 -0.063430  \n",
      "2 -0.210795  0.033078  \n",
      "3 -0.001754  0.030465  \n",
      "4 -0.133461 -0.018460  \n",
      "5 -0.194415  0.056091  \n",
      "6 -0.187919 -0.000546  \n",
      "7 -0.151253  0.069468  \n",
      "8  0.199739  0.134757  \n",
      "9  0.156559 -0.129395  \n"
     ]
    }
   ],
   "source": [
    "# Transform the data using the optimal number of components\n",
    "X_reduced = PCA(n_components=n_components).fit_transform(X_df_scaled)\n",
    "\n",
    "# Create a DataFrame with the reduced data\n",
    "principalDf = pd.DataFrame(data=X_reduced)\n",
    "print(principalDf.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(principalDf, Y_df, test_size=0.2, random_state=42)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_df, Y_df, test_size=0.2, random_state=21)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different classes in y_train: 3\n",
      "Unique classes: [1 2 3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Find unique classes in y_train\n",
    "unique_classes = np.unique(Y_train)\n",
    "\n",
    "# Count the number of unique classes\n",
    "num_classes = len(unique_classes)\n",
    "\n",
    "print(\"Number of different classes in y_train:\", num_classes)\n",
    "print(\"Unique classes:\", unique_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing to the next lower value if the particular category does not have 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1: 27 data points\n",
      "Category 2: 5 data points\n",
      "Category 3: 8 data points\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each category in y_train\n",
    "category_counts = Y_train.value_counts().sort_index()\n",
    "\n",
    "# Print the number of data points for each category\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"Category {category}: {count} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 1: 27 data points\n",
      "Category 2: 5 data points\n",
      "Category 3: 8 data points\n"
     ]
    }
   ],
   "source": [
    "# Find the highest value in y_train\n",
    "highest_value = Y_train.max()\n",
    "\n",
    "# Iterate from the highest value in y_train and decrement if its count is less than or equal to 2\n",
    "for category in range(highest_value, 0, -1):\n",
    "    count = (Y_train == category).sum()\n",
    "    if count <= 2 and category > 1:\n",
    "        Y_train[Y_train == category] = category - 1\n",
    "\n",
    "# Print the updated number of data points for each category\n",
    "updated_category_counts = Y_train.value_counts().sort_index()\n",
    "for category, count in updated_category_counts.items():\n",
    "    print(f\"Category {category}: {count} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in /home/theepana/.local/lib/python3.10/site-packages (1.0.2)\n",
      "Requirement already satisfied: imbalanced-learn==0.8.0 in /home/theepana/.local/lib/python3.10/site-packages (0.8.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/theepana/.local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/theepana/.local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/theepana/.local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (3.3.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/theepana/.local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.0.2 imbalanced-learn==0.8.0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn==1.0.2 in /home/theepana/.local/lib/python3.10/site-packages (1.0.2)\n",
      "Requirement already satisfied: imbalanced-learn==0.8.0 in /home/theepana/.local/lib/python3.10/site-packages (0.8.0)\n",
      "Requirement already satisfied: joblib==1.1.0 in /home/theepana/.local/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/theepana/.local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /home/theepana/.local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/theepana/.local/lib/python3.10/site-packages (from scikit-learn==1.0.2) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==1.0.2 imbalanced-learn==0.8.0 joblib==1.1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to oversample the minority classes\n",
    "smote = SMOTE(random_state=35, k_neighbors=2)   \n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Y_df: (50,)\n",
      "Shape of Y_train before reshaping: (40,)\n",
      "Shape of Y_test before reshaping: (10,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Y_df:\", Y_df.shape)\n",
    "print(\"Shape of Y_train before reshaping:\", Y_train.shape)\n",
    "print(\"Shape of Y_test before reshaping:\", Y_test.shape)\n",
    "\n",
    "# Reshape Y_train and Y_test to have a single column\n",
    "Y_train_reshaped = np.reshape(Y_train.values, (-1, 1))\n",
    "Y_test_reshaped = np.reshape(Y_test.values, (-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual  Random_forst_Predicted\n",
      "7        2                       1\n",
      "44       1                       3\n",
      "43       1                       3\n",
      "25       1                       3\n",
      "14       1                       1\n",
      "2        2                       1\n",
      "23       1                       3\n",
      "31       1                       1\n",
      "17       1                       1\n",
      "47       3                       3\n"
     ]
    }
   ],
   "source": [
    "# Choose a Model\n",
    "ensemble_size_random_forest_model = RandomForestClassifier()\n",
    "\n",
    "# # Train the model\n",
    "ensemble_size_random_forest_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred = ensemble_size_random_forest_model.predict(X_test)\n",
    "\n",
    "# Combine y_val and y_val_pred into a DataFrame for comparison\n",
    "comparison_df = pd.DataFrame({'Actual': Y_test, 'Random_forst_Predicted': y_val_pred})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theepana/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Random_forst_Predicted</th>\n",
       "      <th>Random_forst_smote_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Random_forst_Predicted  Random_forst_smote_Prediction\n",
       "7        2                       1                              1\n",
       "44       1                       3                              1\n",
       "43       1                       3                              3\n",
       "25       1                       3                              1\n",
       "14       1                       1                              1\n",
       "2        2                       1                              2\n",
       "23       1                       3                              1\n",
       "31       1                       1                              3\n",
       "17       1                       1                              1\n",
       "47       3                       3                              1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Choose a Model\n",
    "ensemble_size_random_forest_with_smote_model = RandomForestClassifier()\n",
    "\n",
    "# # Train the model\n",
    "ensemble_size_random_forest_with_smote_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5  \n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cross_val_strategy = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation prediction\n",
    "y_val_pred_cv = cross_val_predict(ensemble_size_random_forest_with_smote_model, X_test, Y_test, cv=cross_val_strategy)\n",
    "\n",
    "# Add the to the existing comparison_df\n",
    "comparison_df['Random_forst_smote_Prediction'] = y_val_pred_cv\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Random_forst_Predicted</th>\n",
       "      <th>Random_forst_smote_Prediction</th>\n",
       "      <th>Logistic_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Random_forst_Predicted  Random_forst_smote_Prediction  \\\n",
       "7        2                       1                              1   \n",
       "44       1                       3                              1   \n",
       "43       1                       3                              3   \n",
       "25       1                       3                              1   \n",
       "14       1                       1                              1   \n",
       "2        2                       1                              2   \n",
       "23       1                       3                              1   \n",
       "31       1                       1                              3   \n",
       "17       1                       1                              1   \n",
       "47       3                       3                              1   \n",
       "\n",
       "    Logistic_Predicted  \n",
       "7                    1  \n",
       "44                   3  \n",
       "43                   3  \n",
       "25                   1  \n",
       "14                   1  \n",
       "2                    1  \n",
       "23                   1  \n",
       "31                   1  \n",
       "17                   1  \n",
       "47                   3  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose a Model\n",
    "ensemble_size_logistic_regression_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "ensemble_size_logistic_regression_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred_logistic = ensemble_size_logistic_regression_model.predict(X_test)\n",
    "\n",
    "# Add the logistic regression predictions to the existing comparison_df\n",
    "comparison_df['Logistic_Predicted'] = y_val_pred_logistic\n",
    "\n",
    "# Print the updated DataFrame\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theepana/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Random_forst_Predicted</th>\n",
       "      <th>Random_forst_smote_Prediction</th>\n",
       "      <th>Logistic_Predicted</th>\n",
       "      <th>Logistic_smote_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Random_forst_Predicted  Random_forst_smote_Prediction  \\\n",
       "7        2                       1                              1   \n",
       "44       1                       3                              1   \n",
       "43       1                       3                              3   \n",
       "25       1                       3                              1   \n",
       "14       1                       1                              1   \n",
       "2        2                       1                              2   \n",
       "23       1                       3                              1   \n",
       "31       1                       1                              3   \n",
       "17       1                       1                              1   \n",
       "47       3                       3                              1   \n",
       "\n",
       "    Logistic_Predicted  Logistic_smote_Prediction  \n",
       "7                    1                          1  \n",
       "44                   3                          1  \n",
       "43                   3                          1  \n",
       "25                   1                          1  \n",
       "14                   1                          1  \n",
       "2                    1                          1  \n",
       "23                   1                          1  \n",
       "31                   1                          1  \n",
       "17                   1                          1  \n",
       "47                   3                          1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choose a Model\n",
    "ensemble_size_logistic_regression_with_smote_model = LogisticRegression()\n",
    "\n",
    "# # Train the model\n",
    "ensemble_size_logistic_regression_with_smote_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5  \n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cross_val_strategy = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation prediction\n",
    "y_val_pred_cv = cross_val_predict(ensemble_size_logistic_regression_with_smote_model, X_test, Y_test, cv=cross_val_strategy)\n",
    "\n",
    "# Add the to the existing comparison_df\n",
    "comparison_df['Logistic_smote_Prediction'] = y_val_pred_cv\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Random_forst_Predicted</th>\n",
       "      <th>Random_forst_smote_Prediction</th>\n",
       "      <th>Logistic_Predicted</th>\n",
       "      <th>Logistic_smote_Prediction</th>\n",
       "      <th>SVM_Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Random_forst_Predicted  Random_forst_smote_Prediction  \\\n",
       "7        2                       1                              1   \n",
       "44       1                       3                              1   \n",
       "43       1                       3                              3   \n",
       "25       1                       3                              1   \n",
       "14       1                       1                              1   \n",
       "2        2                       1                              2   \n",
       "23       1                       3                              1   \n",
       "31       1                       1                              3   \n",
       "17       1                       1                              1   \n",
       "47       3                       3                              1   \n",
       "\n",
       "    Logistic_Predicted  Logistic_smote_Prediction  SVM_Predicted  \n",
       "7                    1                          1              1  \n",
       "44                   3                          1              1  \n",
       "43                   3                          1              1  \n",
       "25                   1                          1              1  \n",
       "14                   1                          1              1  \n",
       "2                    1                          1              1  \n",
       "23                   1                          1              1  \n",
       "31                   1                          1              1  \n",
       "17                   1                          1              1  \n",
       "47                   3                          1              1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a Model\n",
    "ensemble_size_svm_model = SVC()\n",
    "\n",
    "# Train the model\n",
    "ensemble_size_svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_val_pred_svm = ensemble_size_svm_model.predict(X_test)\n",
    "\n",
    "# Add the SVM predictions to the existing comparison_df\n",
    "comparison_df['SVM_Predicted'] = y_val_pred_svm\n",
    "\n",
    "# Print the updated DataFrame\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/theepana/.local/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Random_forst_Predicted</th>\n",
       "      <th>Random_forst_smote_Prediction</th>\n",
       "      <th>Logistic_Predicted</th>\n",
       "      <th>Logistic_smote_Prediction</th>\n",
       "      <th>SVM_Predicted</th>\n",
       "      <th>SVM_smote_Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Random_forst_Predicted  Random_forst_smote_Prediction  \\\n",
       "7        2                       1                              1   \n",
       "44       1                       3                              1   \n",
       "43       1                       3                              3   \n",
       "25       1                       3                              1   \n",
       "14       1                       1                              1   \n",
       "2        2                       1                              2   \n",
       "23       1                       3                              1   \n",
       "31       1                       1                              3   \n",
       "17       1                       1                              1   \n",
       "47       3                       3                              1   \n",
       "\n",
       "    Logistic_Predicted  Logistic_smote_Prediction  SVM_Predicted  \\\n",
       "7                    1                          1              1   \n",
       "44                   3                          1              1   \n",
       "43                   3                          1              1   \n",
       "25                   1                          1              1   \n",
       "14                   1                          1              1   \n",
       "2                    1                          1              1   \n",
       "23                   1                          1              1   \n",
       "31                   1                          1              1   \n",
       "17                   1                          1              1   \n",
       "47                   3                          1              1   \n",
       "\n",
       "    SVM_smote_Prediction  \n",
       "7                      1  \n",
       "44                     1  \n",
       "43                     1  \n",
       "25                     1  \n",
       "14                     1  \n",
       "2                      1  \n",
       "23                     1  \n",
       "31                     1  \n",
       "17                     1  \n",
       "47                     1  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Choose a Model\n",
    "ensemble_size_svm_with_smote_model = SVC()\n",
    "\n",
    "# # Train the model\n",
    "ensemble_size_svm_with_smote_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "num_folds = 5  \n",
    "\n",
    "# Define the cross-validation strategy\n",
    "cross_val_strategy = StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation prediction\n",
    "y_val_pred_cv = cross_val_predict(ensemble_size_svm_with_smote_model, X_test, Y_test, cv=cross_val_strategy)\n",
    "\n",
    "# Add the to the existing comparison_df\n",
    "comparison_df['SVM_smote_Prediction'] = y_val_pred_cv\n",
    "\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model as a pickle file\n",
    "model_directory = \"../model_pickle/ensemble_size\" \n",
    "if not os.path.exists(model_directory):\n",
    "    os.makedirs(model_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the already existing pickle file from the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ../model_pickle/ensemble_size/svm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "def delete_files_in_directory(directory):\n",
    "    try:\n",
    "        # List all files in the directory\n",
    "        files = os.listdir(directory)\n",
    "        \n",
    "        # Iterate over each file\n",
    "        for file_name in files:\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            \n",
    "            # Check if the path is a file (not a directory)\n",
    "            if os.path.isfile(file_path):\n",
    "                # Delete the file\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted: {file_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "delete_files_in_directory(model_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total predictions: 10\n",
      "Correctly classified predictions for Random Forest: 4\n",
      "Correctly classified predictions for Logistic Regression: 6\n",
      "Correctly classified predictions for SVM: 7\n",
      "Correctly classified predictions for Random Forest with smote: 6\n",
      "Correctly classified predictions for Logistic Regression with smote: 7\n",
      "Correctly classified predictions for SVM with smote: 7\n"
     ]
    }
   ],
   "source": [
    "# Total number of predictions (total rows)\n",
    "total_predictions = comparison_df.shape[0]\n",
    "\n",
    "# Number of correctly classified predictions for each model\n",
    "correct_random_forest = (comparison_df['Actual'] == comparison_df['Random_forst_Predicted']).sum()\n",
    "correct_logistic_regression = (comparison_df['Actual'] == comparison_df['Logistic_Predicted']).sum()\n",
    "correct_svm = (comparison_df['Actual'] == comparison_df['SVM_Predicted']).sum()\n",
    "correct_random_forest_with_smote = (comparison_df['Actual'] == comparison_df['Random_forst_smote_Prediction']).sum()\n",
    "correct_logistic_regression_with_smote = (comparison_df['Actual'] == comparison_df['Logistic_smote_Prediction']).sum()\n",
    "correct_svm_with_smote = (comparison_df['Actual'] == comparison_df['SVM_smote_Prediction']).sum()\n",
    "\n",
    "# Print the results\n",
    "print(\"Total predictions:\", total_predictions)\n",
    "print(\"Correctly classified predictions for Random Forest:\", correct_random_forest)\n",
    "print(\"Correctly classified predictions for Logistic Regression:\", correct_logistic_regression)\n",
    "print(\"Correctly classified predictions for SVM:\", correct_svm)\n",
    "print(\"Correctly classified predictions for Random Forest with smote:\", correct_random_forest_with_smote)\n",
    "print(\"Correctly classified predictions for Logistic Regression with smote:\", correct_logistic_regression_with_smote)\n",
    "print(\"Correctly classified predictions for SVM with smote:\", correct_svm_with_smote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the pickle file of the model with highest number of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM model saved as: ../model_pickle/ensemble_size/svm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Determine which model has the highest number of correct predictions\n",
    "models_correct = {\n",
    "    'Random Forest': correct_random_forest,\n",
    "    'Logistic Regression': correct_logistic_regression,\n",
    "    'SVM': correct_svm,\n",
    "    'Random Forest with SMOTE': correct_random_forest_with_smote,\n",
    "    'Logistic Regression with SMOTE': correct_logistic_regression_with_smote,\n",
    "    'SVM with SMOTE': correct_svm_with_smote,\n",
    "}\n",
    "\n",
    "best_model = max(models_correct, key=models_correct.get)\n",
    "\n",
    "# Save the corresponding model to a pickle file\n",
    "if best_model == 'Random Forest':\n",
    "    model_filename = os.path.join(model_directory, 'random_forest_model.pkl')\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(ensemble_size_random_forest_model, f)\n",
    "    print(\"Random Forest model saved as:\", model_filename)\n",
    "elif best_model == 'Random Forest with SMOTE':\n",
    "    model_filename = os.path.join(model_directory, 'random_forest_with_smote_model.pkl')\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(ensemble_size_random_forest_with_smote_model, f)\n",
    "    print(\"Random Forest with SMOTE model saved as:\", model_filename)\n",
    "elif best_model == 'Logistic Regression':\n",
    "    model_filename = os.path.join(model_directory, 'logistic_regression_model.pkl')\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(ensemble_size_logistic_regression_model, f)\n",
    "    print(\"Logistic Regression model saved as:\", model_filename)\n",
    "elif best_model == 'SVM':\n",
    "    model_filename = os.path.join(model_directory, 'svm_model.pkl')\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(ensemble_size_svm_model, f)\n",
    "    print(\"SVM model saved as:\", model_filename)\n",
    "\n",
    "elif best_model == 'Logistic Regression with SMOTE':\n",
    "    model_filename = os.path.join(model_directory, 'logistic_regression_with_smote_model.pkl')\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(ensemble_size_logistic_regression_with_smote_model, f)\n",
    "    print(\"Logistic Regression with SMOTE model saved as:\", model_filename)\n",
    "elif best_model == 'SVM with SMOTE':\n",
    "    model_filename = os.path.join(model_directory, 'svm_with_smote_model.pkl')\n",
    "    with open(model_filename, 'wb') as f:\n",
    "        pickle.dump(ensemble_size_svm_with_smote_model, f)\n",
    "    print(\"SVM with SMOTE model saved as:\", model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
